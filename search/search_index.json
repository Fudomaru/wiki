{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83e\udde0 Digital Dojo","text":"<p>\u201cThe faintest ink is better than the best memory.\u201d</p> <p>Welcome to my Digital Dojo \u2014 a living system where I train, test, and document everything I learn. It\u2019s not a blog. It\u2019s not a portfolio. It\u2019s my external brain, structured for growth and reuse.  </p>"},{"location":"#what-this-is","title":"What this is","text":"<ul> <li>Foundations \u2192 Core knowledge in Linux, networking, and system internals.  </li> <li>Security \u2192 Playbooks, toolbelt, and fundamentals of my cybersecurity practice.  </li> <li>Homelab \u2192 Designs, services, and experiments running in my own network hive.  </li> <li>Challenges \u2192 Notes and walkthroughs from CTFs and wargames (HTB, THM, OTW).  </li> <li>Projects \u2192 Active builds like Void Linux configs, EchoSnare hardware, and this dojo itself.  </li> <li>Notes \u2192 References, cert prep, media, and my personal warboard.  </li> </ul>"},{"location":"#how-to-use-this-space","title":"How to use this space","text":"<p>Some notes are polished guides. Others are rough sketches. That mix is intentional: this Dojo reflects the grind of learning \u2014 theory, practice, and failure included.  </p> <p>If you\u2019re new here: - Start at Foundations to see how I structure my base knowledge. - Jump to Security or Challenges if you want action. - Explore Projects for ongoing builds.  </p> <p>Don\u2019t just read. Fork ideas. Steal commands. Break things. That\u2019s the spirit of the Dojo.</p>"},{"location":"about/","title":"About","text":"<p>I\u2019m Fudomaru \u2014 system administrator, cybersecurity apprentice, and relentless learner. This dojo is the trail I leave behind: not polished for show, but raw, evolving, and real.  </p>"},{"location":"about/#why-i-built-this","title":"Why I built this","text":"<ul> <li>To externalize my memory \u2014 ink over neurons.  </li> <li>To document everything I touch until I own it.  </li> <li>To practice mastery by stripping away fluff and getting to first principles.  </li> </ul> <p>This is not just a wiki. It\u2019s my forge.  </p>"},{"location":"about/#what-drives-me","title":"What drives me","text":"<ul> <li>The elegance of a lean, suckless system \u2014 nothing wasted.  </li> <li>The thrill of tearing into a CTF or a vulnerable box.  </li> <li>The belief that you don\u2019t know something until you can rebuild it from scratch.  </li> </ul> <p>Clarity is power. Every page here is me sharpening mine.  </p>"},{"location":"about/#the-endgame","title":"The endgame","text":"<p>I\u2019m not chasing titles. I\u2019m building mastery. Offensive security, bug bounty, red/blue team craft \u2014 I want it all under my skin.  </p> <p>I know where I stand now, and I know how far there is to climb. That gap doesn\u2019t discourage me. It fuels me.  </p> <p>If you\u2019re here, steal what you find. Twist it. Break it. Make it yours. That\u2019s the only way to master anything.</p>"},{"location":"auto/deploy/","title":"MkDocs Auto-Deploy Script (Powershell)","text":""},{"location":"auto/deploy/#overview","title":"Overview","text":"<p>Automates committing and deploying changes to my Digital Dojo. I build this as a first step to understanding and using a real CI/CD for this project.  For that I needed to solve going to every command by hand. But I didn't want to start using any fancy tool for this simple task. So I decided to make this simple script to automate it.  </p>"},{"location":"auto/deploy/#functional-breakdown","title":"Functional Breakdown","text":"<p>Here I am going to break down what I put into this script: </p>"},{"location":"auto/deploy/#1-location","title":"1. Location","text":"<p>I wanted this to be portable and usable without much of a hustle. So I put the script right into the repo of this page. This way I can always use it as long as I pulled the repo to work on it.  I needed to make sure it runs from the right place: the rood of my repo. To get this location in Powershell I used the following:  </p> <pre><code>$ScriptPath = Split-Path -Path $MyInvocation.MyCommand.Definition -Parent\n$WikiRoot = Join-Path $ScriptPath \"..\" | Resolve-Path\nSet-Location $WikiRoot \n</code></pre>"},{"location":"auto/deploy/#2-git-commit-comment","title":"2. Git Commit Comment","text":"<p>To actually use git commit I have to have a comment of what I am commiting. I wanted to solve this by using an argument I can just put in after the script to make it feel like a real command. That wasn't good enough. When I tried it and it worked, I thought it would be enough.  But even the second try I just forgot about the comment. So I needed a fallback method. And what better option then just let the script ask the user for the Commit Message. That would look like that: </p> <pre><code>if ($args.Length -gt 0 -and -not [string]::IsNullOrWhiteSpace($args[0])) {\n$message = $args[0]\n} else {\n$message = Read-Host \"Enter commit message\"\n}\n</code></pre>"},{"location":"auto/deploy/#3-git-operations","title":"3. Git Operations","text":"<p>This is actually the most straight forward. Just the git commands I normally use by hand. But I did not want to make it quite as easy for myself. So I tried myself with some error catching and outputting what was successful and what failed. All in all I just used a simple try catch with an output of what was currently running when it failed ($_). This gives always gives me a good idea of where the error happend, and let me look at the right thing to try to figure out what went wrong. Also I put the $message variable I got in the previouse part as the commit message.  </p> <pre><code>try {\n    git add .\n    git commit -m \"$message\"\n    if ($?) {\n        Write-Host \"Commit successful\"\n    } else {\n        Write-Host \"Commit failed\"\n    }\n\n    git push\n    if ($?) {\n        Write-Host \"Push successful\"\n    } else {\n        Write-Host \"Push failed\"\n    }\n}\ncatch {\n    $errorMessage = \"An error occurred at $(Get-Date): $_\"\n    Write-Host $errorMessage\n}\n</code></pre>"},{"location":"auto/deploy/#4-githup-pages","title":"4. GitHup Pages","text":"<p>Here I used MkDocs own command gh-deploy.  This command pretty much handels everything I need for me.  First it builds the actual site.  That would be the same as running <code>mkdocs build</code>.  Then it pushes this build to a seperate branch in my repo.  This way I do not have to have the build site in my main branch,  and just tell GitHub to use the seperate branch to deploy from.  This works like a charme, without a lot of hassle so far.  I put this right after my git operations.  </p> <pre><code>mkdocs gh-deploy\n    if ($?) {\n        Write-Host \"Deployment successful\"\n    } else {\n        Write-Host \"Deployment failed\"\n    }\n</code></pre>"},{"location":"auto/deploy/#future-ideas","title":"Future Ideas","text":"<ul> <li> <p>Building in local logging to get more information and maintain everything cleanly for building a full CI/CD. </p> </li> <li> <p>Timestemping inside the commit message and log output. </p> </li> </ul>"},{"location":"challenges/overview/","title":"Overview","text":"<p>Challenges are where theory turns into struggle.  This section is not about polished systems or long-term structures.  It is about the fights I pick for their own sake:  capture-the-flag exercises, wargames,  reverse engineering puzzles, cryptography problems,  and any other tests that demand focus and persistence.</p> <p>I take on challenges for two reasons.  First, the thrill.  There is something addictive about failing repeatedly  and then finding the one path that works.  The moment of success after breaking through  resistance is what keeps me coming back.  Second, the learning.  The write-ups I keep here are not trophies.  They are tools.  Writing down each step forces me to understand what happened,  why it worked, and how I can explain it clearly to myself and others.</p> <p>Every entry will reflect how I approached the problem:  sometimes methodical, sometimes improvisational,  sometimes driven by curiosity more than efficiency.  The important part is not following a fixed formula  but documenting the reality of the process.  Mistakes and dead ends matter just as much as clean solutions.</p> <p>This section also ties into the rest of my work.  When I use a specific tool or method,  I will link back to its deeper documentation.  In the same way,  tools can point forward to challenge write-ups  that show them in practice.  The result is a two-way map:  concepts supported by examples,  and examples grounded in concepts.</p> <p>The challenges collected here are not about external recognition.  They are my battleground for exploration and growth.  Each write-up is a trace of the fight, the frustration,  and the moment when the lock finally turned.</p>"},{"location":"challenges/overthewire/bandit/","title":"bandit","text":""},{"location":"challenges/overthewire/bandit/#level-0","title":"Level 0","text":"<p>So first of all: The setup: OvertheWire is something I found as a good way to get started with CTFs.  Bandit is a simple Linux machine, setup in a way, where each \"flag\" you find is the password for the next level. With this password you can access the machine over SSH, using the level as a username. It is aimed at absolute beginners, teaching the basics of Linux and playing CTFs.  For each level you get a list with new introduced commands, which can help you with figuring out what to do. </p>"},{"location":"challenges/overthewire/bandit/#level-0-level-1","title":"Level 0 \u2192 Level 1","text":"<p>The first level is mainly to get the setup right. It explains that you connect over SSH over port 2220 to bandit.labs.overthewire.org. The username is bandit0 and the password for the first level is given -&gt; also bandit0.  </p>"},{"location":"challenges/overthewire/bandit/#my-setup","title":"My Setup:","text":"<p>I don't really want to miss out with the Linux experience, so I use WSL2 on my Windows machine. It worked like a charm. </p>"},{"location":"challenges/overthewire/bandit/#new-commands","title":"New Commands","text":"<p>For this there was only one command given: SSH This is used to get a secure remote access to another machine. You use this general format: <code>ssh username@connection.address</code> In this case that would look like this: <code>ssh bandit0@bandit.labs.overthewire.org</code></p>"},{"location":"challenges/overthewire/bandit/#my-solutions","title":"My Solutions","text":"<p>I think for this the most important step is to not forget about the port. At first I wanted to just skip reading and try things out, thinking of the way a port is put in an URL. My first try was this: <code>ssh bandit0@bandit.labs.overthewire.org:2220</code> That was obviously wrong. So I did have to figure out what the right way was. I wanted to improve in figuring out this the right way, so instead of looking it up online, I opened the man pages. And shortly after that I found it. I had to use a -p flag to give it the port to use. So I got connected with: <code>ssh -p bandit0@bandit.labs.overthewire.org:2220</code> </p> <p>So I was connected. It was a nice greeting in consol, giving a bit more information on the game.  </p> <p>But I wasn't done.  </p> <p>There was still something missing. The flag, or to be correct: The password for the next level. I started just looking around. With <code>ls</code> I found the conveniently placed readme file. I looked at it with <code>cat readme</code> and there it was: the FLAG!</p>"},{"location":"challenges/overthewire/bandit/#level-1-level-2","title":"Level 1 \u2192 Level 2","text":""},{"location":"challenges/overthewire/bandit/#new-commands_1","title":"New Commands","text":"<p>ls , cd , cat </p>"},{"location":"challenges/overthewire/bandit/#my-solutions_1","title":"My Solutions","text":"<p>I am always suprised on how easy it is to make regular things seam special. It was practically the same thing then the level before. This time the file just wasn't called \"readme\", but \"-\". So just tiping in the normal command wouldn't work. But this time I actually had the problem before. So I did the following: <code>cat ./-</code></p>"},{"location":"challenges/overthewire/bandit/#level-2-level-3","title":"Level 2 \u2192 Level 3","text":""},{"location":"challenges/overthewire/bandit/#my-solutions_2","title":"My Solutions","text":"<p>Since there where no new commands, and in the level description it told me the file name with the flag, I just went on trying <code>cat</code> again. This time went pretty easy for me, since I accidently found the right answer. Sometimes I am pretty lazy, so I use tab to autocomplete a lot. And here it saved me from figuring out on my own how to deal with spaces in filenames. <code>cat spaces\\ in\\ this\\ filename</code></p>"},{"location":"challenges/overthewire/bandit/#level-3-level-4","title":"Level 3 \u2192 Level 4","text":""},{"location":"challenges/overthewire/bandit/#my-solutions_3","title":"My Solutions","text":"<p>No new commands. From the description it was about finding a \"hidden\" file. For this I used <code>cd</code> to get to the folder, and then used the following to show the hidden file: <code>ls -al</code> I know technically I only need the -a to see all, but I do like the look of -l, and it is a lot better for me to just remember -al like I want to see al(l). Then it was just the now typical <code>cat</code> to get to the flag. </p> <p>For most Terminals you can right click somewhere in the Terminal to eighter Copy or Past. Helped me a lot for all these flags.</p>"},{"location":"challenges/overthewire/bandit/#level-4-level-5","title":"Level 4 \u2192 Level 5","text":""},{"location":"challenges/overthewire/bandit/#new-commands_2","title":"New Commands","text":"<p>file</p>"},{"location":"challenges/overthewire/bandit/#my-solutions_4","title":"My Solutions","text":"<p>So again: No new commands, so I guess I can just <code>cat</code> all the files in there. Or so I tought. I was really surprised to find output in front of my bash setup. It wasn't too bad, and just brute forcing my way though all 10 files, it was easy to find the human readable file and the flag.  </p>"},{"location":"challenges/overthewire/bandit/#but","title":"but","text":"<p>I couldn't let it be. So I started searching for to figure out if a file is human readable first. It felt like that would be the right solution. So after thinking about it, and trying to find a clear path to \"human readable\" in the help of different commands, I setteled on the file command. It tells me what something is, and maybe I can tell from the type which is the right one. This is what I ended up using, and it only put one file as ASCII instead of data or a PGP Secret Sub-Key.  <code>file ./*</code></p>"},{"location":"challenges/overthewire/bandit/#level-5-level-6","title":"Level 5 \u2192 Level 6","text":""},{"location":"challenges/overthewire/bandit/#new-commands_3","title":"New Commands","text":"<p>find</p>"},{"location":"challenges/overthewire/bandit/#my-solutions_5","title":"My Solutions","text":"<p>So for this I had to do a bit more reading. I kinda looked into the <code>find</code> command for the last level, but since <code>file</code> seamed to work so good I stopped at that. So in the Level description I got following clue: - human-readable - 1033 bytes in size - not executable Taking my time, going though the man page of find, the first thing useable I got was <code>-size</code>. With this you can search for files with a specific size. For me that meant trying it out and seeing how much I got back, just filtering with the size. I run: <code>find . -size 1033c</code> </p>"},{"location":"challenges/overthewire/bandit/#level-6-level-7","title":"Level 6 \u2192 Level 7","text":""},{"location":"challenges/overthewire/bandit/#my-solutions_6","title":"My Solutions","text":"<p>For this I was greeted with a new search. But this time in a bigger haystack. The whole server. The clues this time: - owned by user bandit7 - owned by group bandit6 - 33 bytes in size</p> <p>So first I had to try the same thing I did Level 5: <code>find / -size 33c</code> This found me a whole lot of different stuff. So I had to go to the next step and figure out how to search for ownership. Back to the <code>man</code> page for me. But I didn't wanted to try to read though everything again. So I thought to be really clever figured out how to search on the <code>man</code> pages. This is done with <code>/ WhatYouWantToSearch</code>. With this it was a lot easier to find out the right command to find the user and group. <code>find / -user bandit7 -group bandit6 -size 33c</code> But still there where way to many files, most of which the permission was denied to me anyway. Going though it, with most of them I had no permissions to look at them anyway. So a quick google search came up with this to check the return code. Then it saves everything that is coded with an standard error (2) to the dedicated place for deletion: <code>find / -user bandit7 -group bandit6 -size 33c 2&gt;/dev/null</code> </p>"},{"location":"challenges/overthewire/bandit/#level-7-level-8","title":"Level 7 \u2192 Level 8","text":""},{"location":"challenges/overthewire/bandit/#new-commands_4","title":"New Commands","text":"<p>grep, strings, base64</p>"},{"location":"challenges/overthewire/bandit/#my-solutions_7","title":"My Solutions","text":"<p>So for this level there where a whole lot of new commands. The Info for this was as follows: The password for the next level is stored in the file data.txt next to the word millionth That meant I now what to do: <code>cat data.txt | grep millionth</code></p>"},{"location":"challenges/overthewire/bandit/#level-8-level-9","title":"Level 8 \u2192 Level 9","text":""},{"location":"challenges/overthewire/bandit/#new-commands_5","title":"New Commands","text":"<p>sort, uniq </p>"},{"location":"challenges/overthewire/bandit/#my-solutions_8","title":"My Solutions","text":"<p>So same set up, but the only line of text that occurs only once. For this I imidiatly went to the <code>sort</code> command. I thought that would make it easy. But I was wrong. Probably I could just go though the output and find the line that only occurs once. But I want it clean. If at all possible just giving me the one line I need. I went looking, but didn't find anything in the sort command. Back to the list with new commands. Kind of ashamed I saw that the next command is called <code>uniq</code>. If that is not made for finding something only existing once in the file. After reading though the man page, I figured I would need to use both. In the end it looked something like that: <code>sort data.txt | uniq -u</code></p>"},{"location":"challenges/overthewire/bandit/#level-9-level-10","title":"Level 9 \u2192 Level 10","text":""},{"location":"challenges/overthewire/bandit/#new-commands_6","title":"New Commands","text":"<p>string</p>"},{"location":"challenges/overthewire/bandit/#my-solutions_9","title":"My Solutions","text":"<p>So I have a data.txt, but it is all gibberish. Again needing to go back to the description. It is supposed to be the only human readable string preceded by several =. For me the imidiat problem is that several is not very specific. But leaving that for the end, I needed to find some good way to look for the right part. I though for the equal sign I can just use <code>qrep</code>. Sadly that wouldn't want to work. Back to the commands. Just checking the next in line, since they seam to come in order, gave me this final answer: <code>strings data.txt | grep \"==\"</code></p>"},{"location":"challenges/overthewire/bandit/#level-10-level-11","title":"Level 10 \u2192 Level 11","text":""},{"location":"challenges/overthewire/bandit/#new-commands_7","title":"New Commands","text":"<p>base64  </p>"},{"location":"challenges/overthewire/bandit/#my-solutions_10","title":"My Solutions","text":"<p>Going though the description first this time I learned, that the data this time  is base64 encoded. So it seams it was pretty straight forward. Reading though the docu for <code>base64</code> and building a functioning command to use it. <code>base64 -d data.txt</code></p>"},{"location":"challenges/overthewire/bandit/#level-11-level-12","title":"Level 11 \u2192 Level 12","text":""},{"location":"challenges/overthewire/bandit/#new-commands_8","title":"New Commands","text":"<p>tr  </p>"},{"location":"challenges/overthewire/bandit/#my-solutions_11","title":"My Solutions","text":"<p>With this I had a bit more problems. I feel like I have heared it somewhere before, so I search online for what this actually is. This is how I found ROT13. With that knowledge I just tried looking at the next command. <code>tr</code> is for translating or deleting charaters in a text. So I knew what I had to do. Delete every letter with the corresponding one. <code>cat data.txt | tr 'A-Za-z' 'N-ZA-Mn-za-m'</code> </p>"},{"location":"challenges/overthewire/bandit/#level-12-level-13","title":"Level 12 \u2192 Level 13","text":""},{"location":"challenges/overthewire/bandit/#new-commands_9","title":"New Commands","text":"<p>tar, gzip, bzip2, xxd  </p>"},{"location":"challenges/overthewire/bandit/#my-solutions_12","title":"My Solutions","text":"<p>So for this the info for the level recomanded to make a directory to work at. I did as I was told. Then I started working my way though everything saving every step of the way. First I converted the hex dump back with: <code>xxd -d data</code> Afterwards I always look what conversion was used with <code>file</code>, then changed the name to have the apropriat ending with <code>mv</code> and used the fitting decompression command. This I needed to do 10 times until finally -&gt; filetype: ASCII Finally I was done and had the password.  </p>"},{"location":"challenges/overthewire/bandit/#level-13-level-14","title":"Level 13 \u2192 Level 14","text":""},{"location":"challenges/overthewire/bandit/#new-commands_10","title":"New Commands","text":"<p>ssh, telnet, nc, openssl, s_client, nmap</p>"},{"location":"challenges/overthewire/bandit/#my-solutions_13","title":"My Solutions","text":"<p>This was pretty exciting for me. I am a big fan of using keys and what happens when it gets into the wrong hands. This might be why I never saved the password for level 14. I copied the privat key and used it to connect directly to the bandit14 account. But I do know you are supposed to connect to bandit14 from your bandit13 account. The command for that would be: <code>ssh -i sshkey.private -p 2220 bandit14@localhost</code></p>"},{"location":"challenges/overthewire/bandit/#level-14-level-15","title":"Level 14 \u2192 Level 15","text":""},{"location":"challenges/overthewire/bandit/#new-commands_11","title":"New Commands","text":"<p>nc</p>"},{"location":"challenges/overthewire/bandit/#my-solutions_14","title":"My Solutions","text":"<p>For this I was really unsure what to do at first. Okay that is not quite true. The level description actually tells me exactly what to do. However, I was unsure how to send something to a port.   This means I went to the internet to figure it out. And found out that I can use netcat for it. So I connected to the port using <code>nc localhost 30000</code> and send the password.  And promt I got the new password for bandit15.  </p>"},{"location":"challenges/overthewire/bandit/#level-15-level-16","title":"Level 15 \u2192 Level 16","text":""},{"location":"challenges/overthewire/bandit/#new-commands_12","title":"New Commands","text":"<p>openssl, s_client</p>"},{"location":"challenges/overthewire/bandit/#my-solutions_15","title":"My Solutions","text":"<p>I used the openSSL s_client to connect to localhost Port 30001.  It worked very smoothly and I send the password for the level. <code>opelssl s_client -connect localhost:30001</code></p>"},{"location":"challenges/overthewire/bandit/#level-16-level-17","title":"Level 16 \u2192 Level 17","text":""},{"location":"challenges/overthewire/bandit/#new-commands_13","title":"New Commands","text":"<p>nmap</p>"},{"location":"challenges/overthewire/bandit/#my-solutions_16","title":"My Solutions","text":"<p>First I scanned the given portspace with nmap also trying to find out the service version. <code>nmap -p 31000-32000 --open -sV localhost</code> The options made the port I needed pretty clear. Next I thought to pretty much just do what I did in the last level. First it did not work and made me really scatch my head.  </p> <p>So after I quite literally smashed my head against the keyboard I finally stumbled upon a solution. I got the connection to the port. I also seam to have the right password, since if I put anything else in, I got the message \"wrong password\" and it kicked me of the connection. But for my password, I only got KEYUPDATED and not the actuall key. I do not know why, but for some reason I could not find out how to look at the key. My solution finally was this: <code>openssl s_client -nocommands -connect localhost:31790</code> With that I avoided the KEYUPDATED information, and instead got the key, which I used like in one of the earlier levels to connect via a SSL key.  </p>"},{"location":"challenges/overthewire/bandit/#level-17-level-18","title":"Level 17 \u2192 Level 18","text":""},{"location":"challenges/overthewire/bandit/#new-commands_14","title":"New Commands","text":"<p>diff</p>"},{"location":"challenges/overthewire/bandit/#my-solutions_17","title":"My Solutions","text":"<p>In comparison with the last level, I felt like it was to easy to work. But I pretty much just used <code>diff</code> to compare the old and new password files. And used the result to log into the next level.  </p>"},{"location":"challenges/overthewire/bandit/#level-18-level-19","title":"Level 18 \u2192 Level 19","text":""},{"location":"challenges/overthewire/bandit/#new-commands_15","title":"New Commands","text":"<p>scp</p>"},{"location":"challenges/overthewire/bandit/#my-solutions_18","title":"My Solutions","text":"<p>So I really liked this idea from the start. Instead of just logging in and finding the password, you are actually logged out. Or at least something like it. When you log in you are imidiatly kicked back out.  </p> <p>So I logged back unto level 17 to see if I can just open the readme file from there. But of course I did not have the permissions to do so. Also I looked at the .bashrc file to see if I can figure out how exactly it works, and how I can get around it. But while looking at it, I had another idea. And so I used folling command to copy the readme file to my own mashine. <code>scp -P 2220 bandit18@bandit.labs.overthewire.org:/home/readme ./bandit18pass</code></p>"},{"location":"challenges/overthewire/bandit/#level-19-level-20","title":"Level 19 \u2192 Level 20","text":""},{"location":"challenges/overthewire/bandit/#my-solutions_19","title":"My Solutions","text":"<p>This one was really straight forward. Just do what you are told in the description and you get the password. But it is made to teach about setuid and what that means, so I need to learn more about it. </p>"},{"location":"challenges/overthewire/bandit/#level-20-level-21","title":"Level 20 \u2192 Level 21","text":""},{"location":"challenges/overthewire/bandit/#my-solutions_20","title":"My Solutions","text":"<p>This I found also really interessting. I couldn't get tmux to work, which is why I will not put it as a new command here. But I do need to learn how to use it. Instead I connected twice, the old fashen way. I just opened two terminals, and connected both over SSH. After that it was just a matter of knowing what to do. On the one side I opened a nc listener, and connected to it with the setuid from the other side. Then I gave the setuid the password, and got the next one out.  </p>"},{"location":"challenges/overthewire/bandit/#level-21-level-22","title":"Level 21 \u2192 Level 22","text":""},{"location":"challenges/overthewire/bandit/#my-solutions_21","title":"My Solutions","text":"<p>For this I got to see cronjobs for the first time, at least in this game. I went to look at the bandit22 job in /etc/con.d/ folder. Here I found a script, and looking at it I just needed to cat the file the password got saved in.  </p>"},{"location":"challenges/overthewire/bandit/#level-22-level-23","title":"Level 22 \u2192 Level 23","text":""},{"location":"challenges/overthewire/bandit/#my-solutions_22","title":"My Solutions","text":"<p>The first part was just like the last level. Looking at the cronjob_bandit23.sh I understood that it did some conversion with md5sum and a sentence that contains a variable from the current whoami command. With that I recreated that converstion using bandit23 as the variable. Then it creates a temp file with this as the name and saves the password from the current user in it. This file I could just cat to see the next flag.  </p>"},{"location":"challenges/overthewire/bandit/#level-23-level-24","title":"Level 23 \u2192 Level 24","text":""},{"location":"challenges/overthewire/bandit/#new-commands_16","title":"New Commands","text":"<p>chmod</p>"},{"location":"challenges/overthewire/bandit/#my-solutions_23","title":"My Solutions","text":"<p>Same trick new rules. This was really fun for me because I really had to think about what permissions really mean and on how many levels they work. I found the script that was run by cron every minute at the same place as the last. It is pretty much to excecute everything in a specific folder and afterwards delete everything in that folder. But one small problem for me. The scripts only runs if the executable is owned my Bandit23. Shouldn't be hard since that is where I already am. But still a bit eye opening for me. The permissions of access is determined by the one that executes, even if the owner of the script is someone else. So I made this to just copy the pass into my temp file: <pre><code>#!/bin/bash\ncat /etc/bandit_pass/bandit24 &gt; /tmp/tmp.RXVt3VhFpv/pass24.txt\n</code></pre> Should work like a charm. I checked the permissions, and the ownership and made sure everything is correct with chmod. After moving it into the write folder, I was waiting for cron to run to get the password. It never happened. Then it tool quite a while for me to figure out, that Bandit24 didn't have permission to write into my temp folder, so as soon as I changed that, everything worked.  </p>"},{"location":"challenges/overthewire/bandit/#level-24-level-25","title":"Level 24 \u2192 Level 25","text":""},{"location":"challenges/overthewire/bandit/#my-solutions_24","title":"My Solutions","text":"<p>For this I could either try ever 10000 possiblities by hand, or I had to come up with a script. So the script it was: <pre><code>#!/bin/bash\n\npassword=\"Old Password\"\n{\n    for pin in $(seq -w 0000 9999); do\n        echo \"$password $pin\"\n    done\n} | nc localhost 30002\n</code></pre></p>"},{"location":"challenges/overthewire/bandit/#level-25-level-26","title":"Level 25 \u2192 Level 26","text":""},{"location":"challenges/overthewire/bandit/#my-solutions_25","title":"My Solutions","text":"<p>So I guess this one I can easily just scip. You get a SSL Key for level 26. That is why it wasnt ever important for me not have the normal shell. I just grabbed the key to the next level and was out of there.    </p>"},{"location":"challenges/overthewire/bandit/#level-26-level-27","title":"Level 26 \u2192 Level 27","text":""},{"location":"challenges/overthewire/bandit/#new-commands_17","title":"New Commands","text":""},{"location":"challenges/overthewire/bandit/#my-solutions_26","title":"My Solutions","text":"<p>Small Window to get <code>more</code>. Use V to get into vim. Use <code>:term shell</code> to normally get a shell in the top half of the termanl.  </p> <p>With that you can get a shell and take what you need, like the password for bandait26 just to be sure to have it. It is saved in the same spot all the other passwords are saved, and can just be read out: <code>cat /ect/bandit_pass/bandit26</code> </p> <p>But that isn't it. You also have to get to bandit27 from here, or get the password somehow. Luckely the solution for that came from Bandit19.  </p>"},{"location":"challenges/overthewire/bandit/#level-27-level-28","title":"Level 27 \u2192 Level 28","text":""},{"location":"challenges/overthewire/bandit/#new-commands_18","title":"New Commands","text":"<p>git</p>"},{"location":"challenges/overthewire/bandit/#my-solutions_27","title":"My Solutions","text":"<p>So for this you have to use <code>git</code> for the first time. But it was not too difficult yet. You have to clone the repo, and make sure you are on the right port. <code>git clone ssh://bandit27-git@bandit.labs.overthewire.org:2220/h ome/bandit27-git/repo</code> After that I just took a look inside, found a readme file, and there was the pass for the next level.  </p>"},{"location":"challenges/overthewire/bandit/#level-28-level-29","title":"Level 28 \u2192 Level 29","text":""},{"location":"challenges/overthewire/bandit/#my-solutions_28","title":"My Solutions","text":"<p>The description for this level was the same as the last one. So I went the same way and cloned the repo, and looked at the readme file. It desplayed the the credentials of Bandit29, but the password was xxxxxxxx. Since I know git is a version control, I thought that is probably the feature for me to learn about. So I looked at the perviouse commits with: <code>git log</code> And in one of them I found the comment fix info leak and in the one before it read add missing data. So of course I needed to look at the add missing data commit just to see what that meant. <code>git checkout &lt;commit-hash&gt;</code> That reverted me back to the version befor the info leak fixing. And now it was just a matter of looking at the readme file, and copying the password.  </p>"},{"location":"challenges/overthewire/bandit/#level-29-level-30","title":"Level 29 \u2192 Level 30","text":""},{"location":"challenges/overthewire/bandit/#my-solutions_29","title":"My Solutions","text":"<p>Same stepps as in the last two levels. But no results. So I looked at the different branches. <code>git branch -r</code> There were severeal branches, but the one that imidiatly took my interest was origin/sploits-dev. So I got to work. <code>git pull origin sploits-dev</code> Pulled the branch I wanted to take a look at. <code>cat exploits/horde5.md</code> Let me see what is in there. But there wasn't anything in there. So I took a look at the previouse versions. There had to be something, but after reading the comment add some silly exploit, just for shit and giggles I knew. They played with me. So I went back to look at the other branches. I saw the branch origion/dev and thought to myself: Since the readme file said for password not in Production that would be a strong hint, that maybe the dev branch already has something. So I want to the dev branch and looked at the readme file, and found the password. <code>git fetch origin dev</code> <code>git switch dev</code> <code>cat README.md</code></p>"},{"location":"challenges/overthewire/bandit/#level-30-level-31","title":"Level 30 \u2192 Level 31","text":""},{"location":"challenges/overthewire/bandit/#my-solutions_30","title":"My Solutions","text":"<p>Same same. Just cloned the repo, looked at the log and the branches. And found nothing. After a while of searching online, what all you can do with git, I found tags. I looked at the tags and found: secret <code>git tag</code> <code>git show secret</code> </p>"},{"location":"challenges/overthewire/bandit/#level-31-level-32","title":"Level 31 \u2192 Level 32","text":""},{"location":"challenges/overthewire/bandit/#my-solutions_31","title":"My Solutions","text":"<p>Again I cloned the repo and looked at the readme file. This one had a really interesting description of what I needed to do. I had to upload a file with specific conditions. So I got to work.  <pre><code>echo 'May I come in?' &gt; key.txt\n</code></pre> I also needed to delete the <code>*.txt</code> from the .gitignor file to get everything to work.  Then it was just: <pre><code>git add .\ngit commit \"something clever\"\ngit push\n</code></pre> And I got the next password back. </p>"},{"location":"challenges/overthewire/bandit/#level-32-level-33","title":"Level 32 \u2192 Level 33","text":""},{"location":"challenges/overthewire/bandit/#my-solutions_32","title":"My Solutions","text":"<p>This was a lot of fun. When I arrived, I found this: <code>WELCOME TO THE UPPERCASE SHELL</code> So I tought, that should not make too much of a difference. But I was very wrong. Non of the previously learned commands worked. But I could try around and see if I find something good to do. After searching though the web for shell commands that only use uppercase, I pretty much only found the variables. So I looked though them to see what there is. Maybe I can use one of them to escape this uppercase shell, just like the level desciption suggested. I found one: <code>$0</code> With that I was back to something more usefull. But for convinence I wanted more. <code>/bin/bash</code> got me to something I was used too. But there was still the problem with getting the next level password. At least until I noticed that I am already bandit33, so I just went to the usuall place and get my password.  <code>cat /etc/bandit_pass/bandit33</code></p> <p>Conclution</p> <p>With this I got though all of the bandit levels. I think it is an awesome experiance, a lot of fun, and you can learn a lot of the basic commands and structure of a Linux system. Also you get used to the idea of not knowing something, and figuring it out on you own. </p>"},{"location":"foundations/overview/","title":"Foundations","text":"<p>Every system sits on foundations. Most people skip them, chasing tools, commands, and quick wins. But without the bigger picture, you\u2019re just pushing buttons you don\u2019t understand.  </p> <p>This part of the dojo is about systems thinking \u2014 the layers that make everything else possible.  </p>"},{"location":"foundations/overview/#what-belongs-here","title":"What belongs here","text":"<ul> <li>Linux \u2014 my home turf, the kernel, CLI, and internals.  </li> <li>Windows &amp; macOS \u2014 different philosophies, different layers, worth understanding.  </li> <li>Android &amp; iOS \u2014 mobile platforms, their architecture, and security implications.  </li> <li>Networking \u2014 because no system lives alone.  </li> </ul> <p>Maybe later I\u2019ll branch into Unix flavors, FreeBSD, or deeper dives into protocols. The point is the same: see the forest, not just the trees.</p>"},{"location":"foundations/overview/#why-foundations-matter","title":"Why foundations matter","text":"<p>When you\u2019re deep in the weeds of a bug, a config file, or a CTF exploit, it\u2019s easy to forget the structure holding it all together. But every exploit, every optimization, every \u201ctrick\u201d sits on top of something bigger:  </p> <ul> <li>A system call.  </li> <li>A kernel abstraction.  </li> <li>A network handshake.  </li> <li>A design philosophy baked in decades ago.  </li> </ul> <p>If I can trace problems back to those roots, then nothing is really \u201cmagic\u201d anymore.  </p>"},{"location":"foundations/overview/#how-ill-use-this-space","title":"How I\u2019ll use this space","text":"<p>This section isn\u2019t a tutorial library. It\u2019s my map of the territory. Expect diagrams, concepts, and key workflows that explain how the machine actually works.  </p> <p>When I get lost in the bytes, I\u2019ll come back here. This page is my reminder: mastery means never losing sight of the foundations.</p>"},{"location":"foundations/linux/cli-magic/","title":"CLI Magic","text":"<p>These are the commands I reach for when things get real.</p>"},{"location":"foundations/linux/cli-magic/#navigation-discovery","title":"Navigation &amp; Discovery","text":"<ul> <li><code>cd</code></li> <li><code>ls</code></li> <li><code>find</code> </li> <li><code>tree</code></li> <li><code>du</code> </li> <li><code>df</code> </li> <li><code>pwd</code> </li> <li><code>readlink</code> </li> </ul>"},{"location":"foundations/linux/cli-magic/#system-info-process-control","title":"System Info &amp; Process Control","text":"<ul> <li><code>top</code> </li> <li><code>htop</code></li> <li><code>ps</code></li> <li><code>lsof</code></li> <li><code>uptime</code></li> <li><code>free</code></li> <li><code>vmstat</code> </li> <li><code>dmesg</code></li> </ul>"},{"location":"foundations/linux/cli-magic/#file-text-manipulation","title":"File &amp; Text Manipulation","text":"<ul> <li><code>cat</code></li> <li><code>less</code></li> <li><code>head</code></li> <li><code>tail</code></li> <li><code>cut</code></li> <li><code>sort</code></li> <li><code>uniq</code></li> <li><code>awk</code></li> <li><code>sed</code></li> <li><code>wc</code></li> <li><code>xargs</code></li> <li><code>tee</code></li> </ul>"},{"location":"foundations/linux/cli-magic/#permissions-users","title":"Permissions &amp; Users","text":"<ul> <li><code>chmod</code></li> <li><code>chown</code></li> <li><code>usermod</code></li> <li><code>whoami</code></li> <li><code>groups</code></li> <li><code>sudo</code></li> <li><code>passwd</code></li> </ul>"},{"location":"foundations/linux/cli-magic/#networking","title":"Networking","text":"<ul> <li><code>ping</code></li> <li><code>ip</code></li> <li><code>ss</code></li> <li><code>ssh</code></li> <li><code>netstat</code></li> <li><code>dig</code></li> <li><code>nslookup</code></li> <li><code>curl</code></li> <li><code>wget</code></li> <li><code>traceroute</code></li> <li><code>nmap</code></li> <li><code>nc</code></li> </ul>"},{"location":"foundations/linux/cli-magic/#archives-packages","title":"Archives &amp; Packages","text":"<ul> <li><code>tar</code></li> <li><code>zip</code></li> <li><code>unzip</code></li> <li><code>dpkg</code></li> <li><code>apt</code></li> <li><code>rpm</code></li> <li><code>dnf</code></li> <li><code>pacman</code></li> </ul>"},{"location":"foundations/linux/cli-magic/#dangerous-but-useful","title":"Dangerous but Useful","text":"<ul> <li><code>rm -rf</code></li> <li><code>dd</code></li> <li><code>mkfs</code></li> <li><code>mount</code></li> <li><code>umount</code></li> <li><code>kill</code></li> <li><code>pkill</code></li> <li><code>reboot</code></li> <li><code>shutdown</code></li> </ul>"},{"location":"foundations/linux/cli-magic/#misc-meta","title":"Misc &amp; Meta","text":"<ul> <li><code>alias</code></li> <li><code>history</code></li> <li><code>!</code> </li> <li><code>man</code></li> <li><code>which</code></li> <li><code>type</code></li> <li><code>time</code></li> <li><code>yes</code></li> </ul>"},{"location":"foundations/linux/cli-magic/#cat","title":"cat","text":"<p>What it does: It shows what is inside the file you append.  </p> <p>Example: I use it all the time to read out the flag on some CTF's. </p> <p>Tip: Awesomt for any automation, where you want to work with some text inside a file.  Just use <code>cat | secondCommand</code>. That also makes it perfect for searching though large files, like logs, together with <code>grep</code></p>"},{"location":"foundations/linux/cli-magic/#cd","title":"cd","text":"<p>What it does: Let's you move to the directory of your choosing.  </p> <p>Tip: Don't forget about the special usecases:  </p> <ul> <li><code>..</code> move up the file structure</li> <li><code>~</code> move to home directory of the current user</li> <li><code>/</code> move to root, but also let's you move anywhere you want, as long as you know the path</li> </ul>"},{"location":"foundations/linux/cli-magic/#chmod","title":"chmod","text":"<p>What it does: Used to change permissions of a file.</p> <p>Real use case: Whenever you make a script so you are actually able to run it. </p> <p>Example: In the example above, making a file executable, it would like that <code>chmod -x [file]</code></p> <p>Tip: Learning the numbercodes is extremly helpful. First number for the user, second for the group, and last for others. Each digit represents a combination of read (4), write (2), and execute (1). </p>"},{"location":"foundations/linux/cli-magic/#du","title":"du","text":"<p>What it does: Calculates actual disk space used by files and directories. </p> <p>Real use case: Good to identify how the space is used in case of low disk space.  </p> <p>Tip: You can pipe it through <code>sort -rh</code> to sort it by biggest size first. </p>"},{"location":"foundations/linux/cli-magic/#find","title":"find","text":"<p>What it does: Used to search for files in a specifed directory. You can search for all kinds of properties that you already know about it. </p> <p>Real use case: I used it to find the flag while playing OWT Bandit. For the level you got the size and some of the properties of the flag, and had to find it. </p> <p>Example: <code>find / -user bandit7 -group bandit6 -size 33c 2&gt;/dev/null</code> That is how I found the specific flag.  Tip: I really want to remember the 2&gt;/dev/null part for throwing out strerr. </p>"},{"location":"foundations/linux/cli-magic/#htop","title":"htop","text":"<p>What it does: An enhanced, interactive version of <code>top</code> with better visuals and controls. </p> <p>Real use case: Quickly kill, renice, or inspect processes without needing multiple commands</p> <p>Tip: It is really important do learn the short cuts and ways to use it to be effectiv. </p>"},{"location":"foundations/linux/cli-magic/#ls","title":"ls","text":"<p>What it does: Shows the inside of the current directory.</p> <p>Tip: Best used with a <code>-al</code> flag to list all files in long format.</p>"},{"location":"foundations/linux/cli-magic/#nc","title":"nc","text":"<p>What it does: Used for everything concering connections via TCP or UDP. You can do soo much with it that it would probably be to much for this little section, and I need to make a whole page for netcat in the futur. </p> <p>Real use case: Mainly to set up listeners to get a reverse shell. That would look something like this: <code>nc -l 1234</code> Also netcat can be used to connect to some port and set it something manuel or in a script. </p>"},{"location":"foundations/linux/cli-magic/#ping","title":"ping","text":"<p>What it does: Sends an ICMP echo request to a target host. </p> <p>Real use case: Perfect to test if there is a connection. Eighter to the target on the way in, or from the mashine on the way out (by pinging something that is alway reachable)</p> <p>Example: <code>ping 8.8.8.8</code> to try to ping the google DNS server, which should always work if you have connection to the internet. </p> <p>Tip: Is often used to monitor server uptime from afar, by regularly sending a ping. </p>"},{"location":"foundations/linux/cli-magic/#ps","title":"ps","text":"<p>What it does: Prints out the current processes. </p> <p>Real use case: Audit running processes precisely, grep specific patterns, or script behavior. </p> <p>Tip: <code>ps faux</code> shows process hierachy, kind of like tree for files. This really helps with finding out where everything is comming from.  </p>"},{"location":"foundations/linux/cli-magic/#ssh","title":"ssh","text":"<p>What it does: Creates a secure connetion with access to the local terminal. </p> <p>Real use case: Maintaining remote servers where it is not reasonable to have direkt access, and which might not have a GUI.</p> <p>Example: Accessing the Bandit Wargame from OvertheWire: <code>ssh -p 2220 bandit0@bandit.labs.overthewire.org</code> </p>"},{"location":"foundations/linux/cli-magic/#top","title":"top","text":"<p>What it does: Real-time view of system processes and resource usage. </p> <p>Real use case: Monitor CPU and detect runaway processes. </p> <p>Tip: You can press M to sort instantly by memory usage.  </p>"},{"location":"foundations/linux/cli-magic/#tree","title":"tree","text":"<p>What it does: It prints out a skeleton of file system you give it. Awesome to get an overview of where everything lives and to better understand what you are working with.  </p>"},{"location":"foundations/linux/cli-magic/#uniq","title":"uniq","text":"<p>What it does: Filter adjacent matching lines. It is mostly used when you have to omit or report repeating lines. Really helpful to dens down loads of data. </p> <p>Real use case: For me it was alo really helpful in one of the OTW Bandit levels. It was mainly designed to teach the <code>uniq</code> command, so I am really excited to find some more real world use cases. </p>"},{"location":"foundations/linux/networking/","title":"Linux Networking","text":"Warning <p>This page is a placeholder</p>"},{"location":"foundations/linux/networking/#checking-connectivity","title":"Checking Connectivity","text":""},{"location":"foundations/linux/networking/#ping","title":"Ping","text":"<p>Test if a host is reachable. Example: <code>ping -c 4 google.com</code></p>"},{"location":"foundations/linux/networking/#traceroute","title":"Traceroute:","text":"<p>Shows each hop on the path to a host.</p>"},{"location":"foundations/linux/networking/#netstat","title":"Netstat:","text":"<p>Show open ports, listening services. Standard usage: <code>ss -tuln</code> </p>"},{"location":"foundations/linux/networking/#curl","title":"Curl","text":"<p>Verify web service responses.</p>"},{"location":"foundations/linux/networking/#netcat","title":"Netcat:","text":"<p>Swiss Army Knife of network tools. Good for checking for open ports, connecting to one, sending or resiving TCP or UDP packages. </p>"},{"location":"foundations/linux/overview/","title":"Overview","text":""},{"location":"foundations/linux/overview/#introduction","title":"Introduction","text":"<p>This is not a distro war or a kernel hacker\u2019s whitepaper. It\u2019s my learning map \u2014 an outline of how Linux comes alive, from firmware to the point where distributions layer on their own systems.</p> <p>Each phase is in broad strokes: concise enough to fit in my head, but ready to be expanded when I dive deeper. This is my navigation aid when troubleshooting, my checklist when something breaks, and my reminder that while the word \u201cLinux\u201d often means \u201ca whole OS,\u201d the kernel is just one \u2014 very important \u2014 piece.</p>"},{"location":"foundations/linux/overview/#phase-1-firmware-bootloader","title":"Phase 1 \u2013 Firmware &amp; Bootloader","text":"<p>Firmware (BIOS/UEFI) - Runs POST, initializes hardware, and finds the bootloader. - On UEFI systems, reads EFI System Partition to locate bootloader <code>.efi</code> file.  </p> <p>Secure Boot (optional) - Verifies bootloader signatures before handing off control (varies by distro config).</p> <p>Bootloader - Common: GRUB, systemd\u2011boot, LILO (rare now). - Presents boot menu, chooses kernel/initramfs, passes kernel parameters. - Loads Linux kernel and initial RAM disk (initrd/initramfs) into memory.</p>"},{"location":"foundations/linux/overview/#phase-2-kernel-initialization","title":"Phase 2 \u2013 Kernel Initialization","text":"<p>Decompression &amp; Start - Kernel binary unpacks itself into memory and begins executing <code>start_kernel()</code>.</p> <p>Hardware Detection &amp; Drivers - Initializes CPU, memory, timers. - Detects buses (PCI, USB, etc.) and loads built\u2011in or initramfs\u2011supplied drivers.</p> <p>Mount root (temporary) - Mounts initramfs as the initial root filesystem. - Provides space for early userspace tools before the \u201creal\u201d root is mounted.</p> <p>Initramfs Tasks - Loads extra drivers/modules needed to access the real root filesystem. - Sets up device nodes via <code>udev</code> or a minimal equivalent. - Handles disk decryption (LUKS), RAID assembly, or filesystem checks if needed.</p> <p>Switch Root - Mounts the actual root filesystem and pivots away from the initramfs.</p>"},{"location":"foundations/linux/overview/#phase-3-early-userspace-kernel-init-process","title":"Phase 3 \u2013 Early Userspace (Kernel \u2192 Init Process)","text":"<p>Init Process Start - Kernel executes the first process (<code>/sbin/init</code> by default). - Can be <code>systemd</code>, <code>SysV init</code>, <code>OpenRC</code>, <code>runit</code>, <code>s6</code>, etc., depending on the distro.</p> <p>Responsibilities here - Mount essential pseudo\u2011filesystems: <code>/proc</code>, <code>/sys</code>, <code>/dev</code>. - Start early daemons required for the system to function. - Configure basic networking (if set to start this early).</p>"},{"location":"foundations/linux/overview/#phase-4-distribution-layer","title":"Phase 4 \u2013 Distribution Layer","text":"<p>From here, the shared \u201cLinux\u201d story branches into distro\u2011specific policy:</p> <p>Init System &amp; Service Management - <code>systemd</code> (Debian, Fedora, Arch, etc.) - <code>OpenRC</code> (Gentoo, Alpine) - <code>runit</code> (Void Linux) - <code>s6</code> (specialized/minimalist setups)  </p> <p>What the Distro Adds on Top - Default services, daemons, and configuration defaults. - Package manager (APT, DNF, pacman, apk, nix, etc.). - Userland tools and shells (Bash, Zsh, dash). - Graphical stack: X11, Wayland, desktop environments (GNOME, KDE, etc.) or minimal WM.</p> <p>This is the point where two systems both \u201crunning Linux\u201d can behave very differently.</p>"},{"location":"foundations/linux/overview/#phase-5-where-i-go-from-here","title":"Phase 5 \u2013 Where I Go From Here","text":"<ol> <li>Make a Distro List </li> <li> <p>Example: Debian, Arch, Void, NixOS, Fedora, Alpine, Gentoo.  </p> </li> <li> <p>Per\u2011Distro Pages </p> </li> <li>What\u2019s the same?  </li> <li>What\u2019s different (init system, package manager, filesystem layout, service defaults)?  </li> <li>What you can expect when troubleshooting or securing the system.</li> </ol>"},{"location":"foundations/linux/overview/#closing-note","title":"Closing Note","text":"<p>By separating the universal Linux startup from the distro layer, I keep one clean mental model for everything the kernel does \u2014 and avoid mixing it up with the policies and tools each distro bolts on. From firmware to init, the process is surprisingly consistent; after that, it\u2019s all about the choices the distribution makes.</p>"},{"location":"foundations/linux/system-internals/","title":"Prcesses &amp; Signals","text":"Warning <p>This page is a placeholder</p>"},{"location":"foundations/linux/system-internals/#why-this","title":"Why this?","text":"<p>This is a core Linux topic. It is always relevant and opens the door for advanced topics like scripting, scheduling and system recovery. If you don't know how Linux handles processes and how you see and handle them, it is very hard to do anything.  </p>"},{"location":"foundations/linux/system-internals/#what-is-a-process","title":"What is a Process?","text":"<p>A process is a running instance of a program, identified by a PID.  </p>"},{"location":"foundations/linux/system-internals/#basic-commands","title":"Basic Commands:","text":"<p><code>ps aux</code> list all running prcesses <code>top</code> / <code>htop</code> live monitoring <code>kill &lt;PID&gt;</code> kill process by PID <code>pmap &lt;PID&gt;</code> showes memory usage  </p>"},{"location":"foundations/linux/system-internals/#common-signals","title":"Common Signals","text":"Signal Explaination SIGTERM polite kill SIGKILL brute-force, can't be caught SIGINT interrupt SIGSTOP pause SIGCONT resume"},{"location":"foundations/macos/overview/","title":"Overview","text":""},{"location":"foundations/macos/overview/#introduction","title":"Introduction","text":"<p>This is not a deep dive manual or a sysadmin brain dump. It\u2019s my learning map \u2014 an outline of how macOS comes alive, from firmware to Finder.</p> <p>Each phase is distilled into a handful of one\u2011liners: small in scope, but expandable whenever I want to investigate further. It\u2019s my breadcrumb trail when I get lost, my checklist when troubleshooting, and my reminder that there\u2019s no \u201cmagic\u201d in macOS once you follow the chain of events.</p> <p>I\u2019m still learning. This page shows my current mental map \u2014 not mastery of every corner of Darwin and Aqua.</p>"},{"location":"foundations/macos/overview/#phase-1-firmware-boot-loader","title":"Phase 1 \u2013 Firmware &amp; Boot Loader","text":"<p>BootROM / iBoot stage - On Intel Macs: BootROM runs POST, initializes hardware, and finds the EFI System Partition (ESP). - On Apple Silicon: The BootROM is immutable in hardware and runs low\u2011level code to bring up the system\u2011on\u2011chip components.  </p> <p>Secure Boot - Apple Secure Boot verifies the integrity of the boot loader and kernel via Apple\u2011signed signatures. - On T2\u2011equipped Intel Macs, iBoot enforces this; on Apple Silicon, the Secure Enclave participates in validation.  </p> <p>Startup Disk &amp; iBoot - iBoot (Apple\u2019s boot loader) loads the macOS kernel and essential components from the chosen startup volume. - On encrypted volumes with FileVault, authentication happens here before the system disk is unlocked.</p> <p>Pre\u2011kernel drivers (kexts) - Minimal kernel extensions for storage, filesystem (APFS), and bus initialization are loaded \u2014 just enough to mount the root volume.</p>"},{"location":"foundations/macos/overview/#phase-2-kernel-lowlevel-init","title":"Phase 2 \u2013 Kernel &amp; Low\u2011Level Init","text":"<p>XNU Kernel - Hybrid kernel combining Mach microkernel, BSD layer, and I/O Kit. Handles scheduling, memory, IPC, and device management.  </p> <p>I/O Kit - Object\u2011oriented driver framework in C++ that initializes device drivers in dependency order.</p> <p>Root filesystem mount - APFS root volume mounts in read\u2011only mode (in modern macOS), with a separate writable \u201cData\u201d volume merged at runtime.</p> <p>Security &amp; Sandbox frameworks - Mandatory Access Control frameworks (Seatbelt sandbox, SIP) engage early to enforce integrity and privilege limits.</p> <p>launchd handoff - Once kernel space is initialized, control passes to <code>/sbin/launchd</code> \u2014 the master process in user space.</p>"},{"location":"foundations/macos/overview/#phase-3-user-space-initialization","title":"Phase 3 \u2013 User Space Initialization","text":"<p>launchd (PID 1) - Replaces the traditional init. Reads property lists (.plist) to start system services, daemons, and agents. - Manages both system\u2011wide services and per\u2011user agents later in the process.</p> <p>System bootstrap services - WindowServer: Compositor for all on\u2011screen graphics. - configd: Manages dynamic configuration for networking. - notifyd, distnoted: Interprocess notifications. - opendirectoryd: Directory services (local accounts, LDAP, Active Directory integration).</p> <p>Security services - <code>securityd</code> handles keychain and cryptographic operations. - <code>opendirectoryd</code> works with login and authentication.</p>"},{"location":"foundations/macos/overview/#phase-4-login-gui-environment","title":"Phase 4 \u2013 Login &amp; GUI Environment","text":"<p>loginwindow - Displays the macOS login screen, manages authentication (password, Touch ID, Apple Watch unlock). - Invokes authentication backends via OpenDirectory.</p> <p>User session launch - Once authenticated, launchd starts the user\u2019s session\u2011specific agents from <code>~/Library/LaunchAgents</code> and <code>/Library/LaunchAgents</code>.</p> <p>Dock &amp; Finder - Finder provides the desktop metaphor: windows, icons, file management. - Dock launches and switches apps, shows running tasks.</p> <p>SystemUIServer - Draws the menu bar, status items, and handles some system\u2011wide UI interactions.</p>"},{"location":"foundations/macos/overview/#phase-5-core-foundations","title":"Phase 5 \u2013 Core Foundations","text":"<p>File System Layout - <code>/System</code>: Read\u2011only OS binaries (sealed system volume). - <code>/System/Library</code>: Core frameworks, kernel extensions, system daemons. - <code>/Applications</code>: Apple\u2011supplied apps. - <code>/Users</code>: Home directories.</p> <p>Configuration Stores - Property lists (.plist) in Library folders define settings for apps, services, and OS. - Defaults system (<code>defaults</code> command) interacts with these.  </p> <p>Service Management - launchd supervises all system daemons and per\u2011user agents. - Services are defined in plist files with triggers (at login, on demand, after filesystem mount).</p> <p>Security &amp; Identity - Keychain for credentials, certificates, and secure notes. - Gatekeeper enforces app signing and notarization. - System Integrity Protection blocks even root from modifying protected parts of the OS.</p> <p>Networking - Managed by configd and related helpers (networkd, mDNSResponder). - Supports dynamic changes without reboot.</p>"},{"location":"foundations/macos/overview/#closing-note","title":"Closing Note","text":"<p>Walking through the macOS startup sequence turns it from a black box into a chain of deliberate stages \u2014 each with its own artifacts, logs, and vulnerabilities. From immutable BootROM to the responsive Finder desktop, every layer has a place and purpose, and knowing the map lets me troubleshoot, secure, and explore with intent.</p>"},{"location":"foundations/windows/overview/","title":"Overview","text":""},{"location":"foundations/windows/overview/#introduction","title":"Introduction","text":"<p>This page is not a manual and not an expert\u2019s lecture. It is my learning map \u2014 an outline of how Windows comes alive, from firmware to desktop.  </p> <p>Each phase is written in broad strokes, with one-liners that keep the  scope small but leave room to expand later. It\u2019s a reference for me when I get lost, a checklist when I troubleshoot,  and a reminder that nothing in Windows is \u201cmagic\u201d once you trace it  back to its roots.  </p> <p>I\u2019m still learning, and this page shows where I am in that process. It doesn\u2019t mean I know every corner of Windows \u2014 only that I\u2019ve started  to chart the territory.  </p>"},{"location":"foundations/windows/overview/#phase-1-firmware-boot-manager","title":"Phase 1 - Firmware &amp; Boot Manager","text":""},{"location":"foundations/windows/overview/#uefi-frimware","title":"UEFI frimware","text":"<p>Initializes hardware, reads the EFI System Partition, and launches Windows Boot Manager  (\\EFI\\Microsoft\\Boot\\bootmgfw.efi).</p>"},{"location":"foundations/windows/overview/#boot-configuration-bcd","title":"Boot Configuration (BCD)","text":"<p>A registry-like store on the ESP  that tells Boot Manager which Windows to load  and how (debug flags, Safe Mode, etc.).</p>"},{"location":"foundations/windows/overview/#secure-boot-optional","title":"Secure Boot (optional)","text":"<p>UEFI verifies Microsoft-signed boot components  so nothing unsigned runs before the kernel.</p>"},{"location":"foundations/windows/overview/#bitlocker-pre-boot-optional","title":"BitLocker pre-boot (optional)","text":"<p>If the OS volum is encrypted,  TPM/pin/unlock happens here so the loader  can read \\windows\\System32\\drivers... .</p>"},{"location":"foundations/windows/overview/#winloadefi","title":"winload.efi","text":"<p>The OS loader that pulls ntoskrnl.exe, the HAL and BOOT_START drivers from  \\Windows\\System32\\drivers\\ into memory.</p>"},{"location":"foundations/windows/overview/#early-driver-class","title":"Early driver class","text":"<p>Only minial storage, filesystem,  and bus drivers load now,  just enough to mount the system volume.</p>"},{"location":"foundations/windows/overview/#kernel-handoff","title":"Kernel handoff","text":"<p>Control transfers to the kernel  with hardware tables (ACPI, memory map) and loader parameters.</p>"},{"location":"foundations/windows/overview/#phase-2-kernel-hal","title":"Phase 2 \u2013 Kernel &amp; HAL","text":""},{"location":"foundations/windows/overview/#ntoskrnlexe","title":"ntoskrnl.exe","text":"<p>The Windows kernel itself.  Schedules threads, manages memory,  handles interrupts, and enforces security boundaries.  </p>"},{"location":"foundations/windows/overview/#hal-hardware-abstraction-layer","title":"HAL (Hardware Abstraction Layer)","text":"<p>Sits between kernel and raw hardware.  Normalizes differences across CPUs, chipsets,  and boards so higher layers don\u2019t care  about vendor quirks.  </p>"},{"location":"foundations/windows/overview/#system-registry-hive","title":"SYSTEM registry hive","text":"<p>Loaded from disk early,  contains driver/services config (HKLM\\SYSTEM).  Without this, the kernel has no roadmap.  </p>"},{"location":"foundations/windows/overview/#boot_start-drivers","title":"BOOT_START drivers","text":"<p>Critical drivers (storage, filesystem, low-level bus)  that must load before the OS volume is usable.  Examples: disk filter drivers, NTFS.  </p>"},{"location":"foundations/windows/overview/#kernel-mode-initialization","title":"Kernel-mode initialization","text":"<p>Core managers spin up:</p> <ul> <li>Memory Manager \u2192 virtual memory, paging  </li> <li>Process Manager \u2192 basic process/thread structures  </li> <li>I/O Manager \u2192 unified device I/O model  </li> <li>Security Reference Monitor \u2192 enforces permissions and access checks  </li> </ul>"},{"location":"foundations/windows/overview/#transition-to-session-init","title":"Transition to session init","text":"<p>When kernel space is stable,  control is passed to smss.exe (Session Manager),  which marks the boundary into user space.  </p>"},{"location":"foundations/windows/overview/#phase-3-session-initialization-user-space","title":"Phase 3 \u2013 Session Initialization (User Space)","text":""},{"location":"foundations/windows/overview/#smssexe-session-manager-subsystem","title":"smss.exe (Session Manager Subsystem)","text":"<p>First user-mode process.  Creates Session 0 (system)  and Session 1+ (interactive users). Launches core subsystems and sets up paging files,  environment variables,  and handles the transition to user sessions.  </p>"},{"location":"foundations/windows/overview/#csrssexe-clientserver-runtime-subsystem","title":"csrss.exe (Client/Server Runtime Subsystem)","text":"<p>Responsible for console windows, thread creation,  and parts of the Windows graphical subsystem. Critical process \u2014 if it dies, the system blue-screens.  </p>"},{"location":"foundations/windows/overview/#wininitexe-windows-initialization","title":"wininit.exe (Windows Initialization)","text":"<p>Spawns essential system processes:</p> <ul> <li>services.exe (Service Control Manager)  </li> <li>lsass.exe (Local Security Authority)  </li> <li>lsm.exe (Local Session Manager)  </li> </ul>"},{"location":"foundations/windows/overview/#servicesexe-service-control-manager","title":"services.exe (Service Control Manager)","text":"<p>Starts and manages Windows services.  Loads AUTO_START drivers and background services  that are not kernel-level.  </p>"},{"location":"foundations/windows/overview/#lsassexe-local-security-authority-subsystem","title":"lsass.exe (Local Security Authority Subsystem)","text":"<p>Handles authentication (logons, password changes)  and enforces local security policies. Works with SAM (Security Accounts Manager)  and Active Directory in domain setups.  </p>"},{"location":"foundations/windows/overview/#lsmexe-local-session-manager","title":"lsm.exe (Local Session Manager)","text":"<p>Coordinates sessions (system vs. user),  fast user switching, and the framework  used by Remote Desktop / Terminal Services.  </p> <p>Note: Remote Desktop itself is optional  and only starts if enabled  through services.exe in later phases.</p>"},{"location":"foundations/windows/overview/#transition-to-logon","title":"Transition to logon","text":"<p>At this stage, the system is alive  enough for a user to authenticate. Control passes to winlogon.exe,  which handles secure logon.  </p>"},{"location":"foundations/windows/overview/#phase-4-logon-shell-startup","title":"Phase 4 \u2013 Logon &amp; Shell Startup","text":""},{"location":"foundations/windows/overview/#winlogonexe","title":"winlogon.exe","text":"<p>Handles the secure attention sequence (Ctrl+Alt+Del),  spawns the logon UI, and passes credentials to LSASS  for authentication.  </p>"},{"location":"foundations/windows/overview/#logonuiexe","title":"logonui.exe","text":"<p>The graphical logon screen. Collects username/password,  or PIN/biometrics, and hands them off securely  through Winlogon to LSASS.  </p>"},{"location":"foundations/windows/overview/#userinitexe","title":"userinit.exe","text":"<p>Runs after successful authentication. Initializes the user profile, applies logon scripts,  and finally launches the shell.  </p>"},{"location":"foundations/windows/overview/#explorerexe","title":"explorer.exe","text":"<p>The Windows shell: desktop, Start menu, taskbar,  and file explorer. Defines the \u201cWindows experience\u201d  for interactive users.  </p>"},{"location":"foundations/windows/overview/#group-policy-client-gpsvc","title":"Group Policy Client (gpsvc)","text":"<p>If the system is domain-joined, applies computer and user  policies at logon. Can control startup scripts, security  settings, network mappings, and more.  </p>"},{"location":"foundations/windows/overview/#network-services","title":"Network services","text":"<p>At this point, network connectivity is established through  <code>svchost.exe</code>-hosted services such as:</p> <ul> <li>DHCP Client (auto-configure IP)  </li> <li>DNS Client (name resolution)  </li> <li>Workstation Service (network shares, SMB client)  </li> </ul>"},{"location":"foundations/windows/overview/#system-ready","title":"System ready","text":"<p>With the kernel, services, and shell running, the system  is now in a usable state. Optional roles and features  (IIS, RDP, Hyper-V, etc.) are loaded as services  on top of this foundation.  </p>"},{"location":"foundations/windows/overview/#phase-5-core-foundations","title":"Phase 5 \u2013 Core Foundations","text":""},{"location":"foundations/windows/overview/#registry","title":"Registry","text":"<p>A hierarchical database of system and application settings. Key hives include:</p> <ul> <li>HKLM (HKEY_LOCAL_MACHINE) \u2192 system-wide settings  </li> <li>HKCU (HKEY_CURRENT_USER) \u2192 user-specific settings  </li> <li>SYSTEM hive \u2192 driver and service configuration  </li> </ul>"},{"location":"foundations/windows/overview/#file-system-layout","title":"File system layout","text":"<p>Windows relies on a few critical directories:</p> <ul> <li>\\Windows\\System32 \u2192 core executables and DLLs  </li> <li>\\Windows\\SysWOW64 \u2192 32-bit binaries on 64-bit systems  </li> <li>WinSxS (Side-by-Side store) \u2192 keeps multiple versions of system libraries for compatibility  </li> </ul>"},{"location":"foundations/windows/overview/#svchostexe","title":"svchost.exe","text":"<p>A generic host process that loads many Windows services  from DLLs. Multiple instances run, each hosting a group  of related services.  </p>"},{"location":"foundations/windows/overview/#windows-subsystems","title":"Windows subsystems","text":"<p>Compatibility layers that define what kind of applications can run:</p> <ul> <li>Win32 \u2192 the main API for modern Windows applications  </li> <li>WOW64 \u2192 runs 32-bit apps on 64-bit Windows  </li> <li>Legacy POSIX / OS/2 layers (historical) \u2192 no longer default, but once provided compatibility  </li> </ul>"},{"location":"foundations/windows/overview/#authentication-security","title":"Authentication &amp; Security","text":"<ul> <li>LSASS enforces policies, credentials, and tokens  </li> <li>SAM (Security Accounts Manager) holds local accounts  </li> <li>Active Directory support when domain-joined  </li> </ul>"},{"location":"foundations/windows/overview/#system-services","title":"System services","text":"<p>Beyond kernel and drivers, Windows depends on background services  (networking, print spooler, Windows Update, etc.) managed by  the Service Control Manager.  </p>"},{"location":"foundations/windows/overview/#closing-note","title":"Closing note","text":"<p>By walking the startup phases and these core foundations,  Windows is no longer a black box: every layer, from firmware  to shell, sits on knowable structures. This page is both a map and a checklist \u2014 a reminder of  where to look when something breaks, or when you want to  dig deeper into the machinery that makes Windows run.  </p>"},{"location":"homelab/gitea/","title":"Gitea","text":"<p>Gitea runs inside a lightweight LXC container in my Proxmox cluster. It serves as my self-hosted Git server, a place where I can version-control projects, experiment with workflows, and practice enterprise-style DevOps setups. While I also use GitHub, Gitea gives me the independence to run my own infrastructure and build muscle memory for real-world scenarios.</p>"},{"location":"homelab/gitea/#why-gitea","title":"Why Gitea?","text":"<p>At first, I just wanted a safe place to store and manage code without relying solely on third-party services. Over time, I realized Gitea offered much more:  </p> <ul> <li>Enterprise training ground \u2014 It allows me to practice CI/CD pipelines, access control, and repo management like an internal development team would.  </li> <li>Redundancy with GitHub \u2014 Even without a full backup strategy yet, GitHub mirrors provide a safety net while I learn proper backup discipline.  </li> <li>Snapshots for recovery \u2014 Proxmox snapshots give me a fallback if something goes wrong, though I plan to move to a more robust backup system in the future.</li> </ul>"},{"location":"homelab/gitea/#access-and-security","title":"Access and Security","text":"<p>I\u2019ve set up SSH key authentication only, no passwords, across all my machines. My Void Linux laptop and Fedora workstation are both authorized, giving me flexible access. If things ever break badly, I can still reach the container directly through the Proxmox web UI console \u2014 a safety hatch that ensures I\u2019m never locked out.</p>"},{"location":"homelab/gitea/#value-in-my-lab","title":"Value in My Lab","text":"<p>While I treat it like production in daily use, I view this Gitea instance as a learning environment first. It lets me:  </p> <ul> <li>Build habits for self-hosted version control </li> <li>Test real-world practices for developer collaboration </li> <li>Gain confidence in infrastructure management without risking external systems  </li> </ul> <p>Running Gitea in my lab is less about hosting for others and more about proving to myself that I can run, maintain, and secure such a service \u2014 skills directly transferable to enterprise DevOps and cybersecurity work.</p>"},{"location":"homelab/overview/","title":"Homelab","text":""},{"location":"homelab/overview/#overview","title":"Overview","text":"<p>The homelab is the proving ground. It is where theory turns into something that can fail under my hands. I do not chase uptime here, I chase insight.  </p> <p>Every service I deploy, every network I stitch together, every breakage I cause, it all serves one purpose: to learn in a way no book or video could ever give me.  </p> <p>This is not a datacenter. It is not meant to impress with scale or hardware. It is meant to expose me to the complexity of real systems, the tension between stability and change, and the truth that every configuration choice carries both benefits and risks.  </p>"},{"location":"homelab/overview/#why-i-build","title":"Why I Build","text":"<p>I build this lab because control is not given, it is taken. If I want to master systems, I need to run them, misconfigure them, repair them, and push them until they break.  </p> <p>I need a place where mistakes are safe, but lessons are sharp. The homelab gives me that place.  </p> <p>It forces me to balance my two perspectives: as the defender who needs resilience, and as the attacker who seeks the cracks. Only by seeing both can I understand the full picture.  </p>"},{"location":"homelab/overview/#design","title":"Design","text":"<p>I build modular. Every piece should be able to stand alone, but also connect cleanly with others.  </p> <p>The network has firewalls, DNS, version control, and services I actually rely on daily. I design them as if I were setting up the skeleton of a small company.  </p> <p>Because that is what most environments really are: small systems that grow, get patched, bent, and sometimes broken, until they turn into something much larger.  </p> <p>I want to see how that happens in my own hands. Where it works. Where it fails. Where it reveals truths you cannot see on paper.  </p>"},{"location":"homelab/overview/#questions","title":"Questions","text":"<p>The lab is not just machines. It is a diary of questions I keep returning to:  </p> <ul> <li>What is worth building, and why?  </li> <li>Which services actually create value, and which are noise?  </li> <li>How do systems evolve as they scale, and where do they collapse?  </li> </ul> <p>These are not questions I expect to solve once. They grow with the lab. They grow with me. And with every new system I add, they get sharper.  </p>"},{"location":"homelab/pfsense/","title":"pfSense","text":""},{"location":"homelab/pfsense/#purpose","title":"Purpose","text":"<p>A dedicated firewall is essential for any secure environment. Since I don\u2019t yet run a separate physical box, I deployed pfSense as a VM on Proxmox. It might not be the \u201cperfect\u201d option, but it gave me a starting point\u2014and more importantly, a lot of lessons in networking, virtualization, and operational resilience.</p>"},{"location":"homelab/pfsense/#lessons-learned","title":"Lessons Learned","text":"<ul> <li>Networking fundamentals: Clear separation of WAN vs. LAN, NAT in practice, and the difference between stateful and stateless firewalls.  </li> <li>Firewall rules: How small misconfigurations can break all connectivity, and how careful planning is required to avoid accidental lockouts.  </li> <li>Troubleshooting: Handling numerous connectivity issues while learning the pfSense interface.  </li> <li>Proxmox passthroughs: Experimenting with PCI passthrough for network cards, including painful lockouts that taught the importance of backup access methods.  </li> <li>Operational insight: Understanding why enterprises often keep \u201ctemporary\u201d insecure access paths\u2014because they\u2019re left behind during setup and never removed.  </li> </ul>"},{"location":"homelab/pfsense/#setup","title":"Setup","text":"<ul> <li>Running pfSense as a FreeBSD VM inside Proxmox.  </li> <li>Access redundancy: Proxmox web UI console serves as a fallback when network access fails.  </li> <li>Snapshots provide basic resilience, though no dedicated backup system is yet in place.  </li> </ul>"},{"location":"homelab/pfsense/#value","title":"Value","text":"<p>Right now, pfSense provides a baseline of security and\u2014just as importantly\u2014valuable logs to analyze. The real power will come once VLANs are implemented and logs are aggregated into a centralized system for deeper analysis. For me, pfSense is both a protective layer and a training tool.  </p>"},{"location":"homelab/pfsense/#next-steps","title":"Next Steps","text":"<ul> <li>Implement centralized logging and visualization (Grafana or similar).  </li> <li>Build towards a full intrusion detection setup.  </li> <li>Eventually replace the VM with a dedicated hardware firewall for improved reliability and performance.  </li> </ul>"},{"location":"homelab/pfsense/#resilience","title":"Resilience","text":"<p>Snapshots allow quick rollbacks, but long-term, I need to establish a proper backup and recovery strategy. pfSense is training wheels for my network security\u2014but strong enough to carry me forward.  </p>"},{"location":"homelab/pihole/","title":"Pi-hole","text":"<p>Pi-hole runs as an LXC on my Proxmox host.  It\u2019s tiny\u2014just 512 MB RAM, but it has been running without issues.  The container is Ubuntu 22.04 with kernel 6.8.12-13-pve,  updated and managed mostly over SSH rather than the Web UI.  </p>"},{"location":"homelab/pihole/#purpose","title":"Purpose","text":"<p>Pi-hole is my single DNS server.  pfSense points to it and hands it out over DHCP,  making it the authoritative DNS for every device on my network.  It also resolves the internal names of my homelab machines,  giving my lab the feel of a self-contained network  rather than just a collection of boxes.  </p> <p>This was my first deliberate \u201cproduction\u201d service in the lab.  Initially, it was mostly an exercise, adblocking was familiar territory,  and I wanted a stepping stone toward something bigger.  My plan is to pair it with Unbound,  so I can move away from forwarding to Cloudflare  and instead perform my own recursive DNS resolution.  </p>"},{"location":"homelab/pihole/#operation","title":"Operation","text":"<ul> <li>Pi-hole does not handle DHCP, only DNS.  </li> <li>Default blocklist is active, but I don\u2019t spend time tweaking it, since that isn\u2019t the focus.  </li> <li>Updates are performed over SSH. I\u2019ve begun automating this process.  </li> <li>I almost never touch the Web UI.  </li> </ul> <p>Longer term, Pi-hole will feed into a logging/analytics pipeline.  Owning my DNS means I own the query data,  which is invaluable for monitoring, research, and building detection capabilities.  </p>"},{"location":"homelab/pihole/#lessons-learned","title":"Lessons Learned","text":"<p>Running Pi-hole taught me how DNS actually behaves at scale.  I\u2019ve seen firsthand how much traffic flows through DNS  and how caching layers propagate changes.  I now understand how records move through the hierarchy  until consistency is reached,  and how modern DNS resolvers deal with latency and reliability.  </p> <p>I also dug into DNS record types,  name server delegation, and the subtle mechanics of resolution.  One surprising realization:  much of so-called \u201cgeo-blocking\u201d is simply DNS manipulation. There\u2019s no deeper enforcement, just traffic pointed elsewhere.  </p> <p>Pi-hole made DNS real, not just theoretical.  It turned an abstract system into something I can bend, test, and own.  </p>"},{"location":"homelab/proxmox/","title":"Proxmox Hypervisor","text":"<p>I run my homelab on a single Proxmox hypervisor.  It\u2019s not glamorous, but it works,  and that balance between budget, efficiency,  and ambition feels a lot like running a small company.  Every decision costs something, and I have to make it count.</p>"},{"location":"homelab/proxmox/#why-proxmox","title":"Why Proxmox?","text":"<p>When I started, I knew I didn\u2019t want to base my lab on Windows.  My goal is to live in a Linux world,  and Proxmox gave me a way to build on that foundation.  It\u2019s open-source, free for my use case, and backed by a strong community.  More importantly: it forced me to choose.  At some point you stop researching and commit to a tool, and Proxmox became mine.</p>"},{"location":"homelab/proxmox/#hardware","title":"Hardware","text":"<ul> <li>CPU: Intel N95, 4 cores @ 3.40GHz  </li> <li>RAM: 16GB  </li> </ul> <p>Nothing fancy, but it\u2019s more than enough to virtualize multiple systems at once.  I\u2019m still amazed at how much I can run on this single box.</p>"},{"location":"homelab/proxmox/#networking","title":"Networking","text":"<p>One of the decisions I\u2019m proud of was giving this machine dual physical NICs.  I wanted WAN and LAN to be separated in hardware, not just in configuration.  Proxmox itself doesn\u2019t touch those NICs directly,  but instead, I pass them through via PCI passthrough to my pfSense VM.  Proxmox lives on a virtual NIC connected to the LAN side,  which keeps management traffic isolated and feels like a proper enterprise setup.</p>"},{"location":"homelab/proxmox/#administration","title":"Administration","text":"<p>My administrative practices are still developing,  but I already try to keep things disciplined:</p> <ul> <li> <p>Snapshots: I take weekly snapshots of the important VMs.                   Nothing changes much week to week, so this keeps me covered.  </p> </li> <li> <p>Backups: I\u2019m still working on a real backup strategy.                 Snapshots are not backups, and I know I need more resilience.  </p> </li> <li> <p>Philosophy: Virtualization-first.                    No single-use machines, no hardware locked into one function                    if I can help it.  </p> </li> </ul>"},{"location":"homelab/proxmox/#reflections","title":"Reflections","text":"<p>This setup is both a struggle and a triumph.  On one hand, everything rests on a single box,  but if it goes down, my entire lab goes dark.  On the other, the fact that this one little machine can run so much is incredible.  It\u2019s taught me to think like a business:  stretch every resource, make trade-offs, and keep moving forward.</p>"},{"location":"notes/ccna/","title":"CCNA Training","text":"<p>This is going to be my training for the CCNA. I want the cert for the knowledge, the recognizion of my knowledge comes last. The best way to show you knowledge, is by knowing.  </p> <pre><code>Since I don't want to scip anything important, I am going to write a paragraphe about every topic mentioned:\n</code></pre>"},{"location":"notes/ccna/#10-network-fundamentals","title":"1.0 Network Fundamentals","text":""},{"location":"notes/ccna/#11-explain-the-role-and-function-of-network-components","title":"1.1 Explain the role and function of network components","text":""},{"location":"notes/ccna/#11a-routers","title":"1.1.a Routers","text":"<p>Routers are network devices that connect different networks together,  typically acting as the gateway between a local network  and the wider internet.  They operate at Layer 3 of the OSI model,  using IP addresses to determine the best path for forwarding data packets.  By analyzing routing tables and protocols,  routers ensure that traffic reaches  its correct destination across multiple networks.  In most setups,  the router serves as the default gateway  that all outbound traffic must pass through to reach external networks.</p>"},{"location":"notes/ccna/#11b-layer-2-and-layer-3-switches","title":"1.1.b Layer 2 and Layer 3 switches","text":"<p>Layer 2 switch</p> <p>A Layer 2 switch is a smarter alternative to a hub,  operating at the Data Link layer (Layer 2) of the OSI model.  It uses a MAC address table to learn which devices  are connected to which ports,  allowing it to forward Ethernet frames directly to the correct destination.  This reduces unnecessary traffic and improves network efficiency.  If the switch doesn\u2019t yet know the destination MAC address,  it temporarily acts like a hub by broadcasting the frame  to all ports to discover where the device is located.</p> <p>Layer 3 switch</p> <p>A Layer 3 switch combines the high-speed switching of Layer 2 devices  with the routing capabilities of a router,  operating at the Network layer of the OSI model.  It\u2019s designed to route traffic between different VLANs  or subnets within a LAN, using IP addresses to make forwarding decisions.  Unlike traditional routers, Layer 3 switches use hardware-based routing,  which makes them faster and more efficient for internal network traffic.  While routers are ideal for connecting different networks  across the internet, Layer 3 switches are optimized for managing complex,  segmented networks within large organizations.</p>"},{"location":"notes/ccna/#11c-next-generation-firewalls-and-ips","title":"1.1.c Next-generation firewalls and IPS","text":"<p>NGFWs</p> <p>A Next-Generation Firewall (NGFW)  is a more advanced version of a traditional firewall.  While regular firewalls filter traffic  based on IP addresses, ports, and protocols,  NGFWs perform deep packet inspection to identify  which application the traffic belongs to,  allowing them to block or allow traffic at the application layer.  This makes them much more effective  against sophisticated threats in enterprise environments.  NGFWs often include built-in intrusion prevention systems (IPS),  and they support more flexible filtering based on applications,  user identities, and cloud-based threat intelligence.</p> <p>IPS</p> <p>An Intrusion Prevention System (IPS)  is a network security tool designed to detect  and block malicious activity in real time.  Unlike traditional firewalls that rely on static rules,  an IPS analyzes traffic patterns and packet contents to identify known threats,  suspicious behavior, or vulnerabilities being exploited.  It uses threat intelligence, signatures, and behavioral analysis  to dynamically stop attacks before they reach their target.  IPS can be a standalone device or integrated into a Next-Generation Firewall,  adding an extra layer of protection by actively inspecting and responding to threats. not just filtering traffic, but preventing intrusions as they happen.</p>"},{"location":"notes/ccna/#11d-access-points","title":"1.1.d Access points","text":"<p>An Access Point (AP) is the part of a home router  that enables wireless connectivity,  even though we often forget it\u2019s there.  It acts as a bridge between wired Ethernet signals  and wireless 802.11 radio frequency signals,  allowing devices like phones  and laptops to connect to the network without cables.  By converting data from the physical layer into a wireless format,  the AP makes Wi-Fi possible and keeps us connected  to the local network and the internet.</p>"},{"location":"notes/ccna/#11e-controllers-cisco-dna-center-and-wlc","title":"1.1.e Controllers (Cisco DNA Center and WLC)","text":"<p>A network controller is a centralized system  that manages and automates the configuration of multiple network devices.  Instead of logging into each switch, router, or access point manually,  the controller pushes settings, monitors performance,  and enforces policies across the network.  This makes large environments easier to manage and more secure.  Controllers like Cisco DNA Center handle wired and wireless infrastructure,  while Wireless LAN Controllers (WLCs) focus on managing access points.  They communicate with devices using protocols like CAPWAP or APIs,  allowing for real-time control and visibility.  In CCNA, understanding that controllers simplify network operations  and are key to modern, scalable network design.</p>"},{"location":"notes/ccna/#11f-endpoints","title":"1.1.f Endpoints","text":"<p>Endpoints are the devices at the edge of the network  that actually use the services provided by the infrastructure.  These include laptops, phones, servers, IoT devices,  and anything else that sends or receives data. They connect through switches, routers, and access points,  and are identified by IP and MAC addresses.  While they don\u2019t forward traffic like network devices,  they are the origin and destination of all communication.  In CCNA, it\u2019s important to understand  how endpoints behave on the network,  how they get their IPs, and why securing them is critical  since they\u2019re often the most vulnerable part of any setup.</p>"},{"location":"notes/ccna/#11g-servers","title":"1.1.g Servers","text":"<p>Servers are specialized endpoints  that provide resources or services to other devices on the network.  Unlike regular user devices, servers are designed to handle requests  from multiple clients, whether it's hosting websites, managing files,  or running applications.  They often run continuously and are optimized for reliability, scalability, and performance.  In a network, servers are key targets and critical assets,  identified by static IPs and often protected by firewalls and access controls.  For CCNA, it's important to understand how servers fit into the client-server model,  how they communicate over TCP/IP, and how they\u2019re accessed and secured.</p>"},{"location":"notes/ccna/#11h-poe","title":"1.1.h PoE","text":"<p>Power over Ethernet (PoE) is a technology  that allows network cables to carry electrical power along with data.  This means devices like access points, IP cameras, and VoIP phones  can be powered directly through the Ethernet cable,  without needing a separate power supply.  PoE simplifies installation and reduces cable clutter,  especially in places where running electrical wiring is difficult.  For CCNA, you should know that PoE is defined by standards  like IEEE 802.3af and 802.3at,  and that switches can be PoE-enabled to deliver power to connected devices.</p>"},{"location":"notes/ccna/#12-describe-characteristics-of-network-topology-architectures","title":"1.2 Describe characteristics of network topology architectures","text":""},{"location":"notes/ccna/#12a-two-tier","title":"1.2.a Two-tier","text":"<p>The two-tier architecture is a simple and efficient network design  used mostly in smaller environments.  It consists of an access layer, where endpoints connect,  and a distribution layer, which aggregates traffic and applies policies  before sending it to the core or external networks.  This setup reduces complexity and cost,  while still allowing for basic scalability and segmentation.  For CCNA, it\u2019s important to know  that two-tier designs are common in small to medium-sized networks  where performance and simplicity are key.</p>"},{"location":"notes/ccna/#12b-three-tier","title":"1.2.b Three-tier","text":"<p>The three-tier architecture adds a core layer on top of the access and distribution layers.  The core layer handles high-speed backbone traffic  and interconnects multiple distribution blocks.  This design is used in larger enterprise networks  to improve scalability, redundancy, and performance.  Each layer has a clear role:  access connects devices,  distribution enforces policies,  and core ensures fast, reliable transport.  For CCNA, understanding the separation of roles  and traffic flow between layers is essential.</p>"},{"location":"notes/ccna/#12c-spine-leaf","title":"1.2.c Spine-leaf","text":"<p>Spine-leaf is a modern topology used in data centers and high-performance environments.  It consists of leaf switches that connect to endpoints  and spine switches that interconnect all leaf switches.  Every leaf connects to every spine,  creating a non-blocking fabric with predictable latency and bandwidth.  This design supports east-west traffic and scales horizontally.  For CCNA, you should know that spine-leaf replaces traditional hierarchies  in environments where speed, scalability, and redundancy are critical.</p>"},{"location":"notes/ccna/#12d-wan","title":"1.2.d WAN","text":"<p>A Wide Area Network (WAN) connects geographically separated networks,  like branch offices to headquarters or cloud services.  It uses technologies like MPLS, VPNs, and leased lines  to transmit data over long distances.  WANs are slower and more complex than LANs,  but they\u2019re essential for global connectivity.  For CCNA, you need to understand how WAN links are provisioned,  what protocols are used, and how routing adapts  to different bandwidth and latency conditions.</p>"},{"location":"notes/ccna/#12e-small-officehome-office-soho","title":"1.2.e Small office/home office (SOHO)","text":"<p>SOHO networks are compact setups designed for homes or small businesses.  They typically use a single router that combines  routing, switching, wireless access, and sometimes firewall functions.  Devices connect via Ethernet or Wi-Fi,  and internet access is usually through a broadband connection.  For CCNA, it\u2019s important to recognize  how SOHO networks simplify infrastructure,  and how basic security and configuration principles  still apply even in small environments.</p>"},{"location":"notes/ccna/#12f-on-premise-and-cloud","title":"1.2.f On-premise and cloud","text":"<p>On-premise networks run entirely on local infrastructure:  switches, routers, servers are managed by the organization.  Cloud networks, on the other hand,  use remote infrastructure hosted by providers like AWS or Azure.  Many modern setups are hybrid, combining both.  Cloud offers scalability and flexibility,  while on-premise gives control and performance.  For CCNA, you should understand the trade-offs,  how connectivity works between cloud and local networks,  and how services like VPNs and SD-WAN bridge the gap.</p>"},{"location":"notes/ccna/#13-compare-physical-interface-and-cabling-types","title":"1.3 Compare physical interface and cabling types","text":""},{"location":"notes/ccna/#13a-single-mode-fiber-multimode-fiber-copper","title":"1.3.a Single-mode fiber, multimode fiber, copper","text":"<p>Single-mode fiber uses a narrow core  and laser light to transmit data over long distances  with minimal signal loss, ideal for WAN links.  Multimode fiber has a wider core and uses LED light,  making it suitable for shorter distances like within buildings.  Copper cabling, such as twisted-pair Ethernet,  is cost-effective and widely used for short-range connections  but is more susceptible to interference and signal degradation.</p>"},{"location":"notes/ccna/#13b-connections-ethernet-shared-media-and-point-to-point","title":"1.3.b Connections (Ethernet shared media and point-to-point)","text":"<p>Ethernet shared media refers to older network setups  where multiple devices share the same transmission medium,  often leading to collisions.  Point-to-point connections, on the other hand, link two devices directly,  eliminating contention and improving performance.  Modern networks favor point-to-point for reliability and speed.</p>"},{"location":"notes/ccna/#14-identify-interface-and-cable-issues-collisions-errors-mismatch-duplex-andor-speed","title":"1.4 Identify interface and cable issues (collisions, errors, mismatch duplex, and/or speed)","text":"<p>Interface and cable issues can cripple network performance.  Collisions occur in half-duplex environments when devices transmit simultaneously.  Errors like CRC mismatches suggest physical damage or interference.  Duplex mismatches, where one end is full-duplex and the other is half,  cause severe throughput problems.  Speed mismatches can prevent links from forming or degrade performance.  Diagnosing these requires careful interface monitoring and configuration checks.</p>"},{"location":"notes/ccna/#15-compare-tcp-to-udp","title":"1.5 Compare TCP to UDP","text":"<p>TCP is a connection-oriented protocol that ensures reliable delivery  through acknowledgments, retransmissions, and sequencing\u2014perfect for applications  like web browsing and email. UDP is connectionless, faster, and lightweight,  but lacks reliability mechanisms. It\u2019s ideal for real-time applications  like video streaming or DNS, where speed matters more than guaranteed delivery.</p>"},{"location":"notes/ccna/#16-configure-and-verify-ipv4-addressing-and-subnetting","title":"1.6 Configure and verify IPv4 addressing and subnetting","text":"<p>IPv4 addressing assigns unique identifiers to devices on a network.  Subnetting divides a larger network into smaller segments,  improving efficiency and security.  Configuration involves setting IP addresses, subnet masks, and gateways.  Verification uses tools like 'ping', 'ipconfig', or  'show ip interface' to confirm connectivity and correct setup.</p>"},{"location":"notes/ccna/#17-describe-private-ipv4-addressing","title":"1.7 Describe private IPv4 addressing","text":"<p>Private IPv4 addresses are reserved for internal use  and not routable on the public internet.  Ranges include 10.0.0.0/8, 172.16.0.0\u2013172.31.255.255, and 192.168.0.0/16.  These addresses require NAT (Network Address Translation) to communicate externally.  They\u2019re essential for conserving public IP space and securing internal networks.</p>"},{"location":"notes/ccna/#18-configure-and-verify-ipv6-addressing-and-prefix","title":"1.8 Configure and verify IPv6 addressing and prefix","text":"<p>IPv6 uses 128-bit addresses and eliminates the need for NAT  by providing a vast address space.  Configuration includes assigning addresses and prefixes, often using SLAAC or DHCPv6.  Verification involves commands like 'ping6', 'show ipv6 interface', and checking prefix delegation.  Understanding IPv6 is key to future-proofing your network skills.</p>"},{"location":"notes/ccna/#19-describe-ipv6-address-types","title":"1.9 Describe IPv6 address types","text":""},{"location":"notes/ccna/#19a-unicast-global-unique-local-and-link-local","title":"1.9.a Unicast (global, unique local, and link local)","text":"<p>Unicast addresses identify a single interface.  Global unicast is routable across the internet.  Unique local is similar to private IPv4\u2014used internally.  Link-local is automatically assigned and used for communication within the same link.</p>"},{"location":"notes/ccna/#19b-anycast","title":"1.9.b Anycast","text":"<p>Anycast assigns the same address to multiple devices.  The network routes traffic to the nearest device,  improving performance and redundancy\u2014commonly used in DNS and content delivery networks.</p>"},{"location":"notes/ccna/#19c-multicast","title":"1.9.c Multicast","text":"<p>Multicast sends traffic to multiple devices subscribed to a group,  conserving bandwidth compared to broadcasting.  It\u2019s used in streaming and routing protocols like OSPF.</p>"},{"location":"notes/ccna/#19d-modified-eui-64","title":"1.9.d Modified EUI 64","text":"<p>Modified EUI-64 generates an IPv6 interface ID  from a device\u2019s MAC address, automating address assignment.  It ensures uniqueness but can raise privacy concerns,  so temporary addresses are often preferred.</p>"},{"location":"notes/ccna/#110-verify-ip-parameters-for-client-os-windows-mac-os-linux","title":"1.10 Verify IP parameters for Client OS (Windows, Mac OS, Linux)","text":"<p>Verifying IP settings ensures proper network connectivity.  On Windows, use 'ipconfig';  on Mac, 'ifconfig' or 'networksetup';  on Linux, 'ip' a or 'nmcli'.  Check IP address, subnet mask, gateway, and DNS settings to troubleshoot connectivity issues across platforms.</p>"},{"location":"notes/ccna/#111-describe-wireless-principles","title":"1.11 Describe wireless principles","text":""},{"location":"notes/ccna/#111a-nonoverlapping-wi-fi-channels","title":"1.11.a Nonoverlapping Wi-Fi channels","text":"<p>In 2.4 GHz Wi-Fi, channels 1, 6, and 11 are nonoverlapping\u2014using them avoids interference.  In 5 GHz, more channels are available with less overlap, improving performance.</p>"},{"location":"notes/ccna/#111b-ssid","title":"1.11.b SSID","text":"<p>The Service Set Identifier (SSID) is the network name broadcast by an access point.  Devices use it to identify and connect to the correct wireless network.</p>"},{"location":"notes/ccna/#111c-rf","title":"1.11.c RF","text":"<p>Radio Frequency (RF) signals carry wireless data.  Factors like frequency band, signal strength, and interference affect performance.  Understanding RF behavior is crucial for Wi-Fi design.</p>"},{"location":"notes/ccna/#111d-encryption","title":"1.11.d Encryption","text":"<p>Wireless encryption protects data from eavesdropping.  WPA2 and WPA3 are current standards,  using strong algorithms to secure communication between clients and access points.</p>"},{"location":"notes/ccna/#112-explain-virtualization-fundamentals-server-virtualization-containers-and-vrfs","title":"1.12 Explain virtualization fundamentals (server virtualization, containers, and VRFs)","text":"<p>Virtualization abstracts physical resources.  Server virtualization runs multiple OS instances on one machine using hypervisors.  Containers isolate applications with shared OS kernels\u2014lightweight and portable.  VRFs (Virtual Routing and Forwarding) allow multiple routing tables on one device,  enabling network segmentation and multi-tenancy.</p>"},{"location":"notes/ccna/#113-describe-switching-concepts","title":"1.13 Describe switching concepts","text":""},{"location":"notes/ccna/#113a-mac-learning-and-aging","title":"1.13.a MAC learning and aging","text":"<p>Switches learn MAC addresses by examining incoming frames and associating them with ports.  Aging removes inactive entries to keep the table current and efficient.</p>"},{"location":"notes/ccna/#113b-frame-switching","title":"1.13.b Frame switching","text":"<p>Frame switching forwards Ethernet frames based on MAC address lookup.  It\u2019s the core function of Layer 2 switches, enabling fast, targeted delivery.</p>"},{"location":"notes/ccna/#113c-frame-flooding","title":"1.13.c Frame flooding","text":"<p>When a switch doesn\u2019t know the destination MAC,  it floods the frame to all ports except the source.  This helps discover unknown devices but can cause temporary congestion.</p>"},{"location":"notes/ccna/#113d-mac-address-table","title":"1.13.d MAC address table","text":"<p>The MAC address table maps MAC addresses to switch ports.  It\u2019s built dynamically and used to make forwarding decisions.  A well-maintained table ensures efficient traffic flow.</p>"},{"location":"notes/ccna/#20-network-access","title":"2.0 Network Access","text":""},{"location":"notes/ccna/#21-configure-and-verify-vlans-normal-range-spanning-multiple-switches","title":"2.1 Configure and verify VLANs (normal range) spanning multiple switches","text":""},{"location":"notes/ccna/#21a-access-ports-data-and-voice","title":"2.1.a Access ports (data and voice)","text":"<p>Access ports are switch interfaces configured to carry traffic for a single VLAN. Devices like PCs, printers, or IP phones typically connect to access ports. In a voice-enabled setup, the switch can assign one VLAN  for voice traffic (for the phone) and  another for data traffic (for the computer connected through the phone). This separation improves QoS and keeps different traffic types logically isolated.</p>"},{"location":"notes/ccna/#21b-default-vlan","title":"2.1.b Default VLAN","text":"<p>By default, all switch ports belong to VLAN 1. This \u201cdefault VLAN\u201d carries control traffic  such as CDP or STP by default, but in production,  it\u2019s considered a best practice to avoid using VLAN 1 for user traffic. Moving management interfaces and user ports away  from VLAN 1 helps reduce attack surfaces.</p>"},{"location":"notes/ccna/#21c-intervlan-connectivity","title":"2.1.c InterVLAN connectivity","text":"<p>Switches segment networks into VLANs,  but by themselves, VLANs can\u2019t talk to each other. For inter-VLAN communication, a Layer 3 device is required. Usually a router (\u201crouter-on-a-stick\u201d) or a Layer 3 switch is used. This setup allows devices in different VLANs to exchange traffic  while still maintaining logical segmentation.</p>"},{"location":"notes/ccna/#22-configure-and-verify-interswitch-connectivity","title":"2.2 Configure and verify interswitch connectivity","text":""},{"location":"notes/ccna/#22a-trunk-ports","title":"2.2.a Trunk ports","text":"<p>Trunk ports are switch ports that carry traffic for multiple VLANs simultaneously. They use tagging (like 802.1Q) to mark which VLAN each frame belongs to. This allows switches to extend VLANs across multiple devices,  keeping network segmentation consistent.</p>"},{"location":"notes/ccna/#22b-8021q","title":"2.2.b 802.1Q","text":"<p>802.1Q is the IEEE standard for VLAN trunking. It inserts a small tag (4 bytes) into Ethernet frames to identify the VLAN ID. Only trunk ports add and interpret these tags,  while access ports deliver untagged traffic to end devices.</p>"},{"location":"notes/ccna/#22c-native-vlan","title":"2.2.c Native VLAN","text":"<p>On an 802.1Q trunk, one VLAN is designated as the \u201cnative VLAN.\u201d Traffic from this VLAN is sent untagged across the trunk. By default, VLAN 1 is native, but administrators often change it for security reasons. Misconfigurations between switches (mismatched native VLANs)  can cause VLAN leakage and connectivity issues.</p>"},{"location":"notes/ccna/#23-configure-and-verify-layer-2-discovery-protocols-cisco-discovery-protocol-and-lldp","title":"2.3 Configure and verify Layer 2 discovery protocols (Cisco Discovery Protocol and LLDP)","text":"<p>Discovery protocols allow devices to advertise and learn information  about directly connected neighbors. Cisco Discovery Protocol (CDP) is Cisco-proprietary,  while LLDP is an open standard. Both can reveal details like device ID, IP address, platform, and port ID. They\u2019re useful for troubleshooting and documentation,  but in secure environments, administrators may disable them  to avoid leaking network details to attackers.</p>"},{"location":"notes/ccna/#24-configure-and-verify-layer-2layer-3-etherchannel-lacp","title":"2.4 Configure and verify (Layer 2/Layer 3) EtherChannel (LACP)","text":"<p>EtherChannel bundles multiple physical links into one logical connection,  increasing bandwidth and providing redundancy. Layer 2 EtherChannel groups switch ports,  while Layer 3 EtherChannel creates a routed link. LACP (Link Aggregation Control Protocol, IEEE 802.3ad)  is the open standard that negotiates and maintains these bundles. EtherChannel prevents loops  because the bundled ports are treated as a single logical interface by STP.</p>"},{"location":"notes/ccna/#25-interpret-basic-operations-of-rapid-pvst-spanning-tree-protocol","title":"2.5 Interpret basic operations of Rapid PVST + Spanning Tree Protocol","text":""},{"location":"notes/ccna/#25a-root-port-root-bridge-primarysecondary-and-other-port-names","title":"2.5.a Root port, root bridge (primary/secondary), and other port names","text":"<p>Spanning Tree Protocol prevents loops by electing  a root bridge as the central point of the topology. Each non-root switch identifies one root port (its best path to the root bridge)  and assigns roles to its other ports (designated or alternate). A backup root bridge can be configured for redundancy in case the primary fails.</p>"},{"location":"notes/ccna/#25b-port-states-forwardingblocking","title":"2.5.b Port states (forwarding/blocking)","text":"<p>Ports in STP move through several states:  blocking, listening, learning, and forwarding. In Rapid PVST+, convergence is much faster,  with ports transitioning directly to forwarding when conditions are safe. Blocked ports exist to prevent loops  by intentionally disabling redundant paths.</p>"},{"location":"notes/ccna/#25c-portfast","title":"2.5.c PortFast","text":"<p>PortFast allows access ports (like those connecting to PCs)  to skip the normal STP states and go directly to forwarding. This avoids delays during host boot-up and DHCP processes. It should only be enabled on ports facing end devices, never on switch-to-switch links.</p>"},{"location":"notes/ccna/#25d-root-guard-loop-guard-bpdu-filter-and-bpdu-guard","title":"2.5.d Root guard, loop guard, BPDU filter, and BPDU guard","text":"<ul> <li> <p>Root guard prevents a port from becoming the root port, protecting the current root bridge.</p> </li> <li> <p>Loop guard keeps redundant links from accidentally moving into forwarding state if BPDUs stop being received.</p> </li> <li> <p>BPDU filter blocks STP BPDUs from being sent or received on specific ports.</p> </li> <li> <p>BPDU guard immediately shuts down a port if it receives a BPDU, protecting access ports from rogue switches.</p> </li> </ul>"},{"location":"notes/ccna/#26-describe-cisco-wireless-architectures-and-ap-modes","title":"2.6 Describe Cisco Wireless Architectures and AP modes","text":"<p>Cisco wireless networks can be deployed in autonomous or controller-based architectures. In controller-based designs, lightweight APs  connect to a Wireless LAN Controller (WLC),  which centralizes management and policies. AP modes include local mode (serving clients),  monitor mode (scanning for rogue APs),  and flexconnect (remote branch deployments  where APs keep working even if the controller link is down).</p>"},{"location":"notes/ccna/#27-describe-physical-infrastructure-connections-of-wlan-components-ap-wlc-accesstrunk-ports-and-lag","title":"2.7 Describe physical infrastructure connections of WLAN components (AP, WLC, access/trunk ports, and LAG)","text":"<p>Access points typically connect to switch access ports (for client VLANs)  or trunk ports (if multiple SSIDs/VLANs are required). The WLC usually connects via a trunk port, aggregating WLAN traffic from many APs. Link Aggregation Groups (LAG) can be used  between controllers and switches for higher bandwidth and redundancy.</p>"},{"location":"notes/ccna/#28-describe-network-device-management-access-telnet-ssh-http-https-console-tacacsradius-and-cloud-managed","title":"2.8 Describe network device management access (Telnet, SSH, HTTP, HTTPS, console, TACACS+/RADIUS, and cloud managed)","text":"<p>Devices can be managed through different channels:</p> <ul> <li> <p>Console: physical, out-of-band access for initial setup.</p> </li> <li> <p>Telnet: plaintext, insecure, rarely used today.</p> </li> <li> <p>SSH: encrypted, standard for CLI-based management.</p> </li> <li> <p>HTTP/HTTPS: GUI-based management (HTTPS preferred for security).</p> </li> <li> <p>TACACS+ / RADIUS: centralized authentication, authorization, and accounting, integrating with enterprise identity systems.</p> </li> <li> <p>Cloud management: modern controllers allow devices to be managed via cloud dashboards, reducing on-premise overhead.</p> </li> </ul>"},{"location":"notes/ccna/#29-interpret-the-wireless-lan-gui-configuration-for-client-connectivity-such-as-wlan-creation-security-settings-qos-profiles-and-advanced-settings","title":"2.9 Interpret the wireless LAN GUI configuration for client connectivity, such as WLAN creation, security settings, QoS profiles, and advanced settings","text":"<p>Wireless LAN controllers provide a GUI for creating and managing SSIDs (WLANs). Admins configure SSID names,  security policies (WPA2, WPA3, enterprise authentication with RADIUS),  and QoS profiles to prioritize traffic types like voice or video. Advanced settings include client isolation, band steering, and load balancing across APs. Interpreting these correctly ensures clients connect securely and receive appropriate quality of service.</p>"},{"location":"notes/ccna/#30-ip-connectivity","title":"3.0 IP Connectivity","text":"<p>3.1 Interpret the components of routing table 3.1.a Routing protocol code 3.1.b Prefix 3.1.c Network mask 3.1.d Next hop 3.1.e Administrative distance 3.1.f Metric 3.1.g Gateway of last resort</p> <p>3.2 Determine how a router makes a forwarding decision by default 3.2.a Longest prefix match 3.2.b Administrative distance 3.2.c Routing protocol metric</p> <p>3.3 Configure and verify IPv4 and IPv6 static routing 3.3.a Default route 3.3.b Network route 3.3.c Host route 3.3.d Floating static</p> <p>3.4 Configure and verify single area OSPFv2 3.4.a Neighbor adjacencies 3.4.b Point-to-point 3.4.c Broadcast (DR/BDR selection) 3.4.d Router ID</p> <p>3.5 Describe the purpose, functions, and concepts of first hop redundancy protocols</p>"},{"location":"notes/ccna/#40-ip-services","title":"4.0 IP Services","text":"<p>4.1 Configure and verify inside source NAT using static and pools</p> <p>4.2 Configure and verify NTP operating in a client and server mode</p> <p>4.3 Explain the role of DHCP and DNS within the network</p> <p>4.4 Explain the function of SNMP in network operations</p> <p>4.5 Describe the use of syslog features including facilities and levels</p> <p>4.6 Configure and verify DHCP client and relay</p> <p>4.7 Explain the forwarding per-hop behavior (PHB) for QoS, such as classification, marking, queuing, congestion, policing, and shaping</p> <p>4.8 Configure network devices for remote access using SSH</p> <p>4.9 Describe the capabilities and functions of TFTP/FTP in the network</p>"},{"location":"notes/ccna/#50-security-fundamentals","title":"5.0 Security Fundamentals","text":"<p>5.1 Define key security concepts (threats, vulnerabilities, exploits, and mitigation techniques)</p> <p>5.2 Describe security program elements (user awareness, training, and physical access control)</p> <p>5.3 Configure and verify device access control using local passwords</p> <p>5.4 Describe security password policies elements, such as management, complexity, and password alternatives (multifactor authentication, certificates, and biometrics)</p> <p>5.5. Describe IPsec remote access and site-to-site VPNs</p> <p>5.6 Configure and verify access control lists</p> <p>5.7 Configure and verify Layer 2 security features (DHCP snooping, dynamic ARP inspection, and port security)</p> <p>5.8 Compare authentication, authorization, and accounting concepts</p> <p>5.9 Describe wireless security protocols (WPA, WPA2, and WPA3)</p> <p>5.10 Configure and verify WLAN within the GUI using WPA2 PSK</p>"},{"location":"notes/ccna/#60-automation-and-progammability","title":"6.0 Automation and Progammability","text":"<p>6.1 Explain how automation impacts network management</p> <p>6.2 Compare traditional networks with controller-based networking</p> <p>6.3 Describe controller-based, software defined architecture (overlay, underlay, and fabric) 6.3.a Separation of control plane and data plane 6.3.b Northbound and Southbound APIs</p> <p>6.4 Explain AI (generative and predictive) and machine learning in network operations</p> <p>6.5 Describe characteristics of REST-based APIs (authentication types, CRUD, HTTP verbs, and data encoding)</p> <p>6.6 Recognize the capabilities of configuration management mechanisms, such as Ansible and Terraform</p> <p>6.7 Recognize components of JSON-encoded data</p> <p>So this are all the topics. If I know about all of them, I am ready to move to the next phase. </p>"},{"location":"notes/overview/","title":"Notes Overview","text":"<p>Not everything I touch fits cleanly into my categories. Some things are half-formed, others experimental, others just fragments I don\u2019t want to lose. This section is where I drop them.  </p> <p>I don\u2019t filter for polish here \u2014 I filter for honesty. If I\u2019m exploring, struggling, or unsure, it belongs here until I find a better place for it. Sometimes it will grow into a full page under Foundations, Tools, or Projects. Other times, it will stay here as a reminder of where I\u2019ve been.  </p>"},{"location":"notes/overview/#purpose","title":"Purpose","text":"<ul> <li>Catch-all: Anything that doesn\u2019t fit elsewhere, or not yet.  </li> <li>Work-in-progress: Drafts, fragments, experiments.  </li> <li>Honesty: Shows what I\u2019m learning, not just what I\u2019ve mastered.  </li> <li>Trace: Keeps a record of what I touched, even if it never became a full page.  </li> </ul>"},{"location":"notes/overview/#how-ill-use-it","title":"How I\u2019ll use it","text":"<ul> <li>Write first, sort later.  </li> <li>Keep entries short and clear, but don\u2019t worry if they\u2019re incomplete.  </li> <li>Revisit regularly: some notes will migrate, others will stay.  </li> <li>Accept that this section is messy by design.  </li> </ul>"},{"location":"notes/overview/#closing-thought","title":"Closing thought","text":"<p>This section is proof that I\u2019m human. It shows the edges of my learning, not just the polished center. By keeping it open, I leave myself no excuse to avoid writing things down. Every fragment here is better than silence, because silence forgets.  </p>"},{"location":"notes/warboard/","title":"WARBOARD","text":"What is this for? <p>This is a plan for me to keep myself real. I write down what I am currently working on, what is planed next, and what are general ideas for the future.  </p>"},{"location":"notes/warboard/#active-operations","title":"ACTIVE OPERATIONS","text":"Info <p>Tasks that I am currently working on.</p> <ul> <li>Working though OWT Natas and documenting it.</li> <li>Building an Overview page for the Offensive Cybersecurtiy tools I want to learn</li> <li>Making an Overview of the different Sections</li> <li>Working though the learning material of the CCNA</li> </ul>"},{"location":"notes/warboard/#staging-zone","title":"STAGING ZONE","text":"Info <p>Mental RAM. The stuff I am activly thinking on how to put them in.  </p> <ul> <li>Write secontion on setuid, openssl, permissions in linux</li> <li>Writing the generall CyberSec tools section </li> <li>Explaining where I stand in my Nvim Journy</li> </ul>"},{"location":"notes/warboard/#strategic-backlog","title":"STRATEGIC BACKLOG","text":"Info <p>Goals for the long time and bigger projects befor I actually start working on them.  </p> <ul> <li>Page with better explaination on DMZs. </li> <li>Deep-dive into privilege escalation.</li> <li>Getting picture documentation to work</li> <li>List of file formats and what it means and you can do with it. </li> </ul>"},{"location":"notes/warboard/#completed-strikes","title":"COMPLETED STRIKES","text":"Info <p>Trying to keep a brief history and show of what the newes pages are.  </p> <ul> <li>Creating an Overview of the Startup process of the main operating systems (2025-08)</li> <li>Restructure considering my current knowledge (2025-08)</li> <li>Create automation script for deployment and dokumenting it (2025-05)</li> <li>Using Warboard as a way to stay acountable (2025-05)</li> <li>Bandit dokumetation (2025-04)</li> <li>Adding a Logo (2025-04)</li> <li>First draft Cyber Fundamentals (2025-04)</li> <li>Adding Filestructure, Home and About Page (2025-04)</li> <li>Adding Digital Dojo Project (2025-04)</li> </ul>"},{"location":"projects/digital-dojo/","title":"Building a Digital Dojo","text":""},{"location":"projects/digital-dojo/#how-i-built-my-digital-dojo-using-mkdocs","title":"How I Built My Digital Dojo Using MkDocs","text":""},{"location":"projects/digital-dojo/#1-installing-python","title":"1. Installing Python","text":"<ul> <li> <p>First things first: checking if Python was already installed. I tested that by running <code>py --version</code> or <code>python --version</code></p> </li> <li> <p>Since it wasn't installed on my machine, I installed it using: <pre><code>winget install --id Python.Python.3 --source winget\n</code></pre> This was the cleanest, most straightforward way to do it via PowerShell.</p> </li> <li> <p>Then I hit my first bump in the road: <code>py --version</code> worked, but <code>python --version</code> didn\u2019t. So I had to figure out the difference.</p> </li> </ul> Difference between <code>py</code> and <code>python</code> commands <ul> <li>To fix this, I disabled the Microsoft Store\u2019s shortcut under: <pre><code>Settings &gt; Apps &gt; App execution aliases\n</code></pre> That forced <code>python</code> to point to the real install.</li> </ul>"},{"location":"projects/digital-dojo/#py-is-the-launcher-python-is-the-interpreter","title":"<code>py</code> is the launcher. <code>python</code> is the interpreter.","text":"<ul> <li> <p><code>py</code> is a small helper that comes with the official Python install on Windows. Its job is to find and launch the right Python version. </p> </li> <li> <p><code>python</code> is the actual interpreter \u2014 the program that runs your code.</p> </li> </ul>"},{"location":"projects/digital-dojo/#why-does-this-matter","title":"Why does this matter?","text":"<p>Because <code>py</code> usually works even if your PATH isn't set up right. But <code>python</code> might be broken, hijacked, or just point to the wrong thing (like the Microsoft Store version).</p> <p>Bottom line:</p> <ul> <li>Use <code>py</code> when your system is fresh and you\u2019re still figuring things out.</li> <li>But for full control and compatibility (especially with scripts, tools, and virtual environments), make sure <code>python</code> points to your real install \u2014 and then use <code>python</code> from that point forward.</li> </ul> <p>If <code>py</code> is the butler, <code>python</code> is the king. Eventually, you don\u2019t want to talk to the butler anymore.</p>"},{"location":"projects/digital-dojo/#2-installed-mkdocs","title":"2. Installed MkDocs","text":"<ul> <li> <p>This was straightforward. I installed MkDocs using pip:  <pre><code>pip install mkdocs\n</code></pre></p> </li> <li> <p>I picked a good spot for my project folder, navigated into it, and ran:  <pre><code>mkdocs new .\n</code></pre> This initialized a fresh MkDocs site in the current directory. </p> </li> </ul>"},{"location":"projects/digital-dojo/#3-git-github-setup","title":"3. Git &amp; GitHub Setup","text":"<ul> <li> <p>I checked if Git was installed  <pre><code>git --version\n</code></pre> It wasn\u2019t, so I installed it using:  <pre><code>winget install --id git.git -e\n</code></pre></p> </li> <li> <p>Then I configured Git with:  <pre><code>git config --global user.name \"Your Name\"\ngit config --global user.email \"your@email.com\"\n</code></pre></p> </li> <li>I initialized my repo and set up the remote: <pre><code>git init\ngit remote add origin https://github.com/YOUR_USERNAME/my-wiki.git\ngit add .\ngit commit -m \"Initial commit\"\ngit push -u origin main\n</code></pre></li> <li>That\u2019s where I hit the next wall: the push failed. Why? Because I hadn\u2019t set up GitHub authentication on this machine. </li> </ul> GitHub setup <p>Since this was a fresh install, I needed to authenticate with GitHub using SSH:</p> <ul> <li>Generated an SSH key (<code>ssh-keygen</code>) and copied the public key.</li> <li>Added the key to GitHub under Settings &gt; SSH and GPG keys.</li> <li>Switched the Git remote to use SSH:</li> </ul> <pre><code>git remote set-url origin git@github.com:username/repo.git\n</code></pre> <ul> <li>With that out of the way, I built and deployed the site: <pre><code>mkdocs build\nmkdocs gh-deploy\n</code></pre> MkDocs created a gh-pages branch with only the built site and pushed it to GitHub \u2014 ready to be served.</li> </ul>"},{"location":"projects/digital-dojo/#4-whats-next","title":"4. What's Next","text":"<ul> <li>Writing actual content: The infrastructure\u2019s ready. Now comes the real work: documenting ideas, tools, commands, thoughts.</li> <li>Structuring the knowledge: Tags, categories, maybe a TOC plugin. I want a digital brain that grows with me.</li> <li>Styling the site: Playing with themes (starting with Material for MkDocs) and customizing fonts, colors, and layout.</li> </ul>"},{"location":"projects/echosnare/","title":"EchoSnare","text":""},{"location":"projects/echosnare/#vision","title":"Vision","text":"<p>For a while now I have been interested in Networking.  With that a big part of understanding is working out how everything fits together.  And so I started to think about what I can do to understand where I am, and what surrounds me in the Internet.  What paths does my traffic usually follow.  Can I find out where it differs.  And I already have a few good Ideas of how to start mapping out the cables I am using all day long to talk, game, and watch stuff. </p> <p>Now it also happend that I came across something special.  Something that probably always peaked my interest, but I have never really felt ready to dive deeper.  Well I am ready.  I have learned a lot, and I feel ready to get my feet wet trying to really understand what IoT means, what it is and what it can do.  I found an ESP32 Dev board with battery, case, Oled Display and LoRa Modul.  So what do I want to do with it. Everything.  But for now I want to build my own Wifi_Sniffer.</p>"},{"location":"projects/echosnare/#tools-of-the-hunt","title":"Tools of the Hunt","text":"<p>Here are the tools I plan to use for this project. </p>"},{"location":"projects/echosnare/#hardware","title":"Hardware","text":"<ul> <li>ESP32 LoRa V3 Development Board</li> <li>3000mAh LiPo battery</li> <li>Meshtastic case</li> <li>Smartphone (for eventual geotagging)</li> <li>PC running some Linux Distro</li> </ul>"},{"location":"projects/echosnare/#software","title":"Software","text":"<ul> <li>MicroPython</li> <li>Nvim (with MicroPython plugin)</li> <li>rshell</li> <li>ampy</li> </ul>"},{"location":"projects/echosnare/#gameplan","title":"Gameplan","text":""},{"location":"projects/echosnare/#battle-station-setup","title":"Battle Station Setup","text":"<p>This is the first real move in the direction of actually doing something after the planning phase. I need to get my Nvim setup for MicroPython. For that I need to install all the dependicies I will need to finish this projcet. Then I set up my Nvim to have Highlighting, etc. </p>"},{"location":"projects/echosnare/#flash-and-burn","title":"Flash and Burn","text":"<p>Then the next step will be flashing the right firmware to the board.  I also need to find out which firmware I need since I have already read somewhere there might be a problem with promiscuous mode in there.  Next just making sure it works, and I can start getting to work. </p>"},{"location":"projects/echosnare/#wifi-sniffing-core","title":"WIFI Sniffing Core","text":"<p>This is going to be the first step.  For that I need to enable the sniffing.  Then figure out how I can log what I need and how to save it using onboard flash.  And last I would need to figure out good settings and control over the scanning rate and uptime. </p>"},{"location":"projects/echosnare/#oled-display","title":"OLED Display","text":"<p>Next I will be considering what to do with the already integreted display.  Thinking about it there should probably be some way to display the battery level.  And also maybe a count of how many SSID/MAC adresses I have found and saved.  Maybe I can do a percentage of how full the storage is or something like it. </p>"},{"location":"projects/echosnare/#sync-to-base","title":"Sync to Base","text":"<p>The last thing of the offical project is going to be how I handle syncing the data to my server.  Since this is going to be local, I will probably try to make the ESP32 connect to my local Wifi, and then start a sync automatically.  Maybe I find a better way, but the idea is that I can have it with me,  and only worry about charging it.  The rest should be automated. </p>"},{"location":"projects/echosnare/#geotagging","title":"Geotagging","text":"<p>As a bonus I will try to get some location to my scanned data, and maybe start to build a map.  For that my idea is to use my androids GPS.  And for something special the fun Idea I had was to use my phones ability to create a hotspot for a few seconds and encode the location in the SSID name,  and later convert it back for some general location based on time. </p>"},{"location":"projects/overview/","title":"Projects Overview","text":"<p>This section is for my projects \u2014 personal builds, experiments, and long-term work. They\u2019re rarely finished, and they don\u2019t have to be. What matters is that I\u2019ve started, shaped something, and left a trace I can return to.  </p> <p>Projects evolve over time. Sometimes I revisit them after months, sometimes years. This section helps me pick up where I left off, without having to rediscover everything. It\u2019s not only about documenting progress, but also about remembering the why behind each project.  </p>"},{"location":"projects/overview/#purpose","title":"Purpose","text":"<ul> <li>Record: Keep track of what I\u2019ve built and where I paused.  </li> <li>Context: Capture the purpose and motivation, not just the technical details.  </li> <li>Evolution: Show how projects change, stall, or grow over time.  </li> <li>Revisiting: Make it easier to restart or improve without losing momentum.  </li> </ul>"},{"location":"projects/overview/#how-ill-use-it","title":"How I\u2019ll use it","text":"<ul> <li>Write down projects as I work on them, no matter how small or unfinished.  </li> <li>Focus on clarity: what I did, why I did it, and where I left off.  </li> <li>Return to pages when I continue a project, updating them instead of starting fresh.  </li> <li>Treat this as a log of my creative and technical journey \u2014 not just successes, but also dead ends.  </li> </ul>"},{"location":"projects/overview/#closing-thought","title":"Closing thought","text":"<p>Every project here is a story in progress. Some will grow into polished systems, others will remain half-built. But all of them matter, because they show the trail of what I\u2019ve explored, created, and learned. This section is my workshop archive: a place where nothing is wasted, because even unfinished work becomes part of the journey.  </p>"},{"location":"projects/void_linux/","title":"Void_Station_Setup","text":""},{"location":"projects/void_linux/#table-of-contents","title":"Table of Contents","text":"<ul> <li> <p><code>Why Void</code></p> </li> <li> <p><code>Pre-Install Decisions</code></p> </li> <li> <p><code>Installation</code></p> </li> <li> <p><code>Post-Install Setup</code></p> </li> <li> <p><code>Graphical Stack</code></p> </li> <li> <p><code>Networking</code></p> </li> <li> <p><code>Final Touches</code></p> </li> <li> <p><code>Lessons learned</code></p> </li> <li> <p><code>Replication Checklist</code></p> </li> </ul>"},{"location":"projects/void_linux/#why-void","title":"Why Void","text":"<p>So for this there can be a lot of reason.  But to be completely honest it comes mostly down to what I found and what sounded interesting.  I have been looking to have something a lot more minimal then my current fedora setup.  But not just minimal, because I still feel that is a bit of a bold statement.  You don't just want something minimal, there is normally a reason even for that.  And with that I am pretty clear:  I want to understand! And the less there is, the more of it you can actually comprehensivly understand.  So starting out with a minimal system, if at all possible staying in the TTY, the possibility is a lot more realistic to actually get how everything works.  To be clear: I do not expect to actually be able to just comprehend the whole linux kernal like that.  But the less I have on top, the less there is to abstract and keep me from actually knowing what is going on. </p> <p>There are a lot more fun things to learn using Void Linux.  But these I figured out after already choosing it, and so I don't want to clame them as my reason. </p>"},{"location":"projects/void_linux/#pre-install-decisions","title":"Pre-Install Decisions","text":"<p>So there had to be a few decisions I had to make before, and for me also during the installation.  The first was choosing the ISO.  But this was relativly easy.  I wanted a clean install without anything.  So even if I would choose a Window Manager later on, I did now want anything like that on my ISO.  Next was the boot method. And there I have to be honest again, since before I started I wanted to see how it workes, I looked though quite a few guides.  Pretty much all of them used the UEFI system.  So that is what I choose. </p> UEFI vs. BIOS <p>So even though I just choose the UEFI because of the information I got.  Mainly BIOS doesn't have a lot of features.  From bigger drives and more partitions. It has also better graphical support and secure boot.  The problem is that I can't really say one of these things are a game breaker for me, so I might have to go back and figure out more details. </p>"},{"location":"projects/void_linux/#installation","title":"Installation","text":"<p>So this was suprisiongly problematic at first. And I still don't really know what went wrong.  First I used the <code>dd</code> command to make the bootable USB form the ISO.  This already impressed me, since I have never used that tool to be honest.  Also a point where I still have a lot of things to learn.  Then booting to the USB, and running <code>void-installer</code> is pretty straight forward. </p> <p>Now I went through the installer one by one, and all seemed pretty logically, I struggled a bit with making sure I have the UEFI partition and choose to use a bit of SWAP too.  Also I wasnt completly sure what groups I would need, so I choose to use almost non, so I could add them later if I can't do something because I am missing them.  That comes back to me understanding what everything is for.  And if you add something because you need it, then you know what it is for by definition. </p>"},{"location":"projects/void_linux/#post-install-setup","title":"Post-Install Setup","text":"<p>So this is where the fun actually begun.  Booting up I was in the tty.  That is pretty much everything I ever wanted from a system.  Reading up on the documentation (https://voidlinux.org) I tried to figure out as much as I could.  But I am still far from understanding everything.</p> <p>The first problem I run into was the font, more spefically the font size.  Don't understand me wrong, I wanted to change the font too, but the size was the acutal problem.  But I couldn't get it to stay persistent for a reboot. To quickly change the the font I used <code>setfont /usr/share/kbd/consolefonts/&lt;font&gt;</code> That works fine, but I needed to find the right config file to change it.  There I did something stupid, which cost me a lot of time. I found the right file to change it very quickly, and just for your info, it is <code>/etc/rc.conf</code> It is pretty self explanatory, just setting the <code>FONT=\"&lt;font&gt;\"</code> to the desired font.  It was also pretty fun to find out that in the tty there isn't really a fontsize.  Since a font in tty is just a bitmap, laying out exactly which bit is part of the letter and which is not, the different size is just a different font. </p> <p>But my problem was that I had a typo in the rc.conf file.  So it did not take it, and I was on the search of how else to change it.  So my big lesson learned is: if it doesn't work as expected, check again.  It might not be that you have the wrong way to do something, it might just be a small mistake costing you sanity.</p> <p>But I was connected to my wifi, and I started updating with <code>xbps-install -Su</code> and installing some basic things I liked.  One of them is neovim. Since I am using NVIM already on my fedora workstation, and I have the setup in my dotfiles repo, I went on trying to connect to that.  For this I installed git and cloned my local dotfiles.  I knew that it probably won't work completly the way I am used to it, since some of my plugins relay on the graphical interface.  Searching it up to be exact it relies on a NerdFont Package and on truecolor.  Since tty is not able to do eighter or, I would just have to get used to it.  To be honest I don't really mind, since it is both just about looks, not about funktionality. </p>"},{"location":"projects/void_linux/#graphical-stack","title":"Graphical Stack","text":"<p>So there we are.  I have set this up with the intention of a tty only minimal system to learn how everything works.  And with that I was pretty much done.  So all that I needed now was to work with it.  But then it started getting to me. I am still in a lot of need for some graphical things.  This is why I needed something.  It needs to be small enough to still fit my feeling of a minimal setup, but I need some basic things to make this my daily driver.  And so I found suckless.  I really liked the idea.  Not just the minimal, from the feeling almost self build setup. I really enjoyed reading there documentation, having to compile it locally also sounded like a lot of fun, and to get to the \"settings\" you just change the code.  That actually sounds exatly like what I want.  To be able to use this system, you have no choice but to understand it.  And I just keeps going like that.  The form of patching also made me smile.  No updates, patches, code changes, and you do what you need to fix things, if you want to. </p> <p>That is why I descided to try my luck.  And I installed not only dwm.  I put ST, Dmenu, and slstatus. At least for now.  I want to try to set everything up and see how that feels.  Everything of that setup brings me closer to the metal, having more controle and for that also generates more understanding and knowledge.  And whatever happens afterwards happens. I would love to go to a tty only setup, but I am just not ready yet. </p>"},{"location":"projects/void_linux/#networking","title":"Networking","text":"<p>So my next step is to setup some good networking without installing any more tools.  I am planing on using dmenu, wpa-supplicant, and dhcped.  That and some bash script should be enough to let me create something very similar to a modern network manager. Or at least the part that is mostly used.  Without all the unnessesary bloat, which no one understands, or needs.  Everything Else comes later. </p>"},{"location":"projects/void_linux/#final-touches","title":"Final touches","text":"<p>There are a few things I want to do.  I started with the thing that bortherd me the most. And then I worked form there.  This way I hoped to build up only what really helps me, and what I want visually. </p>"},{"location":"projects/void_linux/#first-visuals","title":"First Visuals","text":"<p>For that reason I startet with slstatus.  The things I wanted to display are only things that I would actually want to look at.  Something that gives me information I need and want to check regularly.  That came out as following: Time and Date, Battery (since it is Laptop), RAM usage. There is one more thing, which is still a to-do.  And that would be some way to show where I am.  But I want that to be mainly for when I am using SSH, just to have a clear way to see on which mashine I am working on.  That set up I have now looks something like this: </p> <pre><code>static const struct arg args[] = {\n    {datetime, \"%s\", \"%d\"},\n    {datetime, \"%s\", \"%T\"},\n    {battery_perc, \"%s%%\", BAT0},\n    {ram_perc, \"%s%%\", NULL},\n}\n</code></pre> <p>Then I also got myself some Nerd Fonts, put the ones I wanted in dwm and in st and fixed the size, to make everything feel more like home.  And directly after that I also installed the fibonacci patch for dwm, because I think that is one of the most efficent layouts I can think of. </p>"},{"location":"projects/void_linux/#lessons-learned","title":"Lessons learned","text":"<p>With this project there are a lot of things I have learned, and am still learning.  But most of them don't really bolong into a \"lessons learned\" section.  I feel like here should mostly belong things that went wrong and taught me something.  Since this is an ongoing experiment, I think there will still be a lot of things that go wrong. So this part is going to be regularly updated with everything I have learned.</p>"},{"location":"projects/void_linux/#minimalism","title":"Minimalism","text":"<p>With this project I feel like the most important lessons I have learned, is the difference people can see in the same idea.  At the beginning, a minimal system mostly sounded like something without a lot of buttons and programs constantly running.  I thought that it could be a really good looking aesthetic.  Less programms already installed.  And maybe I even recognized a smaller ISO file size.  But working with it, and trying to find my way and make this PC my own, I learned what that really means.  It means that there is a whole lot of things that can be made simpler.  Things that work the way they do, because somewhere there is some edge case that needs them to work that way.  But that also adds a huge amount of noise.  And with a minimal setup, it constrains and makes you think about what you actually want and need.  The best example is networking.  There are a lot of things that can be done in networking. And almost all of these things, I dont need for my day to day work.  For a stationary PC, even if it is connected over wlan, I dont need a menu and all these different settings to manage different SSIDs.  I am not moving a stationary PC.  And I am not changing the SSID of my wlan weekly, or even monthly, probably not even every year.  So in this case, every one of these options is noise. </p> <p>I think this one of the best way for me to explain it.  Maybe I can find a better explaination in the future, but for now that needs to be enough.</p>"},{"location":"projects/void_linux/#replication-checklist","title":"Replication Checklist","text":"<p>Get yourself a base image of Void Linux.  Also you need a USB stick without any important data on it.  Burn the ISO on the USB stick using</p> <pre><code>sudo dd if=/path/to/your.iso of=/dev/sdX bs=4M oflag=sync\n</code></pre> <p>Then you just need to start you pc from the USB.  It starts into the live void system, and you are already almost done.  There are now just a few options you need to set and fit to your liking.  For that, I wouls say you do your own research, but I will give you my settings anyway.  After you start the installation process you just run <code>void-installer</code>.  Going though the different options you need to choose your keyboard and network yourself.  For source I used the network with base installation.  Next is the partioning.  I use cfdisk, and cleaned everything form the PC, because I did my backup beforehand.  I made a 1g efi partition, and put everything else into a file system.  The mount points need to be as following: For the boot partition it is <code>/boot/efi</code> and the root partition is just <code>/</code>. Then you have to create a user and and choose which groups you want to be in.  That is also completly your own choice.  Just one thing that helped my decision.  Since I wanted this to learn how everything works, I didn't choose anything.  I know I can log into root if nessesary, and I can put myself to every group I want to if nessesary.  Then you start the installation and you are pretty much done with everything I will decribe here.  From there you choose what you want. </p>"},{"location":"security/fundamentals/","title":"Cybersec Fundamenals","text":""},{"location":"security/fundamentals/#what-is-this-page","title":"What is this Page","text":"<p>This is my personal crash course into cybersecurity. I use it to track concepts, tools and tactis I pick up and get to use efficantly in CTFs and during my learning.  </p> <p>It evolves as I learn!</p>"},{"location":"security/fundamentals/#the-mindset-of-a-hacker","title":"The Mindset of a Hacker","text":"<ul> <li> <p>Thinking outside the box: Try to find as many ways to use tools and systems as you can. There is never the right way, there are only endless possibilities.  </p> </li> <li> <p>The Why is more important then the How: Understanding why something is done, the motivation and psychologie behind it, you find the weak points.  </p> </li> <li> <p>No is not an option: You often get the best results, after nothing works and you have to get creative.  </p> </li> <li> <p>See the System: To figure something out, and really understand it, it is often recommended to take a step back.   </p> </li> <li> <p>Attention to Detail: Pay close attention to every detail and be persistent in figuring out the why.   </p> </li> <li> <p>\"Man lernt nie aus\": This is not just a phrase, it is a philosophy  </p> </li> </ul>"},{"location":"security/fundamentals/#core-concepts-to-understand","title":"Core Concepts to Understand","text":"<ul> <li> <p>CIA Triade: The three core parts to make things secure. Look at this on every level, from singel packages to complete infrastructures. If any is missing, that is where things go wrong.  </p> </li> <li> <p>OWASP Top 10: The most commen vulnarbilities found in the wild. Learn them, know them, and look for them everywhere.  </p> </li> <li> <p>Defense in depth: Layering security strategies, always know that every layer will be breached. So configure every layer like it is the first and last defence.  </p> </li> <li> <p>Privilege escalation: Type of attack where a unauthorized user gains access to more then they should. There are two ways for that, vertical and horizontal. Vertical movement is going up the food ladder, to management and admin. Horizontal means staying on your permission level, but accessing a different user, gaining confidentail data.  </p> </li> <li> <p>Post Exploitation: Don't forget that most seriouse attackers are not done after they get access. They will try to get persistence, escalate privileges, and gather information.  </p> </li> </ul>"},{"location":"security/fundamentals/#tools-i-use","title":"Tools I use","text":"<ul> <li> <p>nmap: Networkscanner of choice. </p> </li> <li> <p>Burp Suite: Package interception, changing and exploring of WebApps on a new level.  </p> </li> <li> <p>John the Ripper: Because weak passwords are still more common then you think.  </p> </li> <li> <p>ffuf: Because Enumerating is at least half of the game.  </p> </li> <li> <p>netcat: The Swiss army knife of raw Networking Connections.  </p> </li> </ul>"},{"location":"security/fundamentals/#my-learning-plan","title":"My Learning Plan","text":"<p>Phase 1: Basics - get as much Hands on as you can. Phase 2: Enumeration - try to learn to understand systems quickly. Phase 3: Exploration - warming up with all the common bugs. Phase 4: Real World - getting my Hands dirty in Bug Bounty</p>"},{"location":"security/overview/","title":"Security","text":"<p>To defend, you have to think like an attacker. To attack, you have to understand what\u2019s worth defending.  </p> <p>This section is where I train that perspective.  No \u201ctips and tricks\u201d, but the mindset and methods  that reveal how systems break and how they hold.  </p>"},{"location":"security/overview/#what-belongs-here","title":"What belongs here","text":"<ul> <li>Fundamentals \u2192 core security principles, models, and mental frameworks.  </li> <li>Toolbelt \u2192 the utilities I train with: scanners, proxies, sniffers, exploit frameworks.  </li> <li>Playbooks \u2192 practical flows: recon, enumeration, exploitation, post-exploitation, and the obstacles that shut each down.  </li> </ul> <p>The focus is offensive security \u2014 but never in isolation. Every exploit I study comes with a shadow: the defense that makes it harder, slower, or impossible.  </p>"},{"location":"security/overview/#why-security-matters-to-me","title":"Why security matters to me","text":"<p>Security isn\u2019t just about keeping bad actors out. It\u2019s about knowing the terrain:  </p> <ul> <li>What do I have that\u2019s valuable?  </li> <li>What path would someone take to get it?  </li> <li>What would make their life hell along the way?  </li> </ul> <p>The old saying holds: know your friends, but know your enemies better. </p> <p>For me, that means documenting every angle \u2014 from the attacker\u2019s first probe to the defender\u2019s last line of resistance.  </p>"},{"location":"security/overview/#how-ill-use-this-space","title":"How I\u2019ll use this space","text":"<p>This isn\u2019t a news feed of CVEs or copy-paste exploits. It\u2019s my personal playbook: evolving, imperfect, and sharpened by practice.  </p> <p>Some notes will be polished \u2014 structured guides, recon flows, tool deep-dives. Others will be messy \u2014 ideas mid-grind, tactics that worked once and failed twice.  </p> <p>That mix is intentional. Real security work isn\u2019t static. Neither is this dojo.  </p>"},{"location":"security/playbooks/recon/","title":"Inital Target Scope","text":"<p>Define what the target is. Find the domains, subdomains, IP range. What Infrastructure do they use, what company profiles are attackable and in scope. This sets the boundaries and makes sure it is clear where the recon begins and where it ends.  </p>"},{"location":"security/playbooks/recon/#engagement-type","title":"Engagement Type","text":"<p>First it is essential to clearly define what are you doing your recon for. What is the goal.  You need to define if you are doing a CTF, a Pentest or if you are going for a bug bounty.</p>"},{"location":"security/playbooks/recon/#rules-of-engagement-roe","title":"Rules of Engagement (RoE)","text":"<p>Take a detailed look in the rules you are to follow. If something is not clear, it needs to be adressed. Is social engineering in scope? Are destructive payloads prohibited? Can you fuzz login forms? What are the time restrictions? It is important that everything is documented and everyone involved understands the rules.  </p>"},{"location":"security/playbooks/recon/#in-scope","title":"In Scope","text":"<p>It need to be clearly defined. What domains, subdomains, etc. can be attackt. What about third-party services? You have to be very clear. </p>"},{"location":"security/playbooks/recon/#out-of-scope","title":"Out of Scope","text":"<p>You also need to define specific services, IPs, domains that are not to be touched. Partners, shared infrastructure or production critical services.  </p>"},{"location":"security/playbooks/recon/#success-criteria","title":"Success Criteria","text":"<p>Also really important to define. You want to know when you are done, when you have done your job. It should be clear, that no system is ever completly save, it always depends a multitude of things if and when it will be owned. But what is actually needed to count it as success. </p>"},{"location":"security/playbooks/recon/#logistics-authorization","title":"Logistics &amp; Authorization","text":"<p>Which accounts are authorized. What about VPN, access tokes. You need a explicit permission to go through with it. What is your point of contact if anything happens. Do you have a \"get out of jail\" card? </p> <p>Warning</p> <p>No moving forward until this part is airtight. </p>"},{"location":"security/playbooks/recon/#passive-recon","title":"Passive Recon","text":"<p>Definition</p> <p>Collecting information without touching the target. Stay a ghost by watching, not touching. The rule is: No traffic hits their servers. </p>"},{"location":"security/playbooks/recon/#osint-open-source-intelligence","title":"OSINT (Open-Source Intelligence)","text":"<p>Tool and techniques:  </p> <ul> <li>crt.sh, CertSpotter, Censys, Shodan, ZoomEye, Hunter.io</li> <li>Employee footprinting  (LinkedIn, GitHub, Twitter)</li> <li>WHOIS &amp; DNS history</li> <li>Archive.org (Wayback Machine)</li> </ul> <p>Trying to extract all public data about the target without making direct contact.  Your Building the dossier befor stepping on the field. </p>"},{"location":"security/playbooks/recon/#subdomain-enumeration","title":"Subdomain Enumeration","text":"<p>Tools: </p> <ul> <li>Amass (passive mode), Subfinder, Assetfinder, Findomain </li> </ul> <p>Sources:</p> <ul> <li>Certificate Transparency Logs</li> <li>Public DNS data aggregation (VirusTotal, dns.bufferover.run) </li> </ul> <p>This is to find potentail subdomains without touching the target. Create a list of possiblities to make the next stepps easier for yourself. </p>"},{"location":"security/playbooks/recon/#dns-enumeration","title":"DNS Enumeration","text":"<ul> <li>Passive DNS record discovery </li> <li>Zone history (SecurityTrails, PassiveTotal)</li> </ul> <p>Helps to understand the infrastruture layout and potentail service endpoints. </p>"},{"location":"security/playbooks/recon/#technologie-figerprinting","title":"Technologie Figerprinting","text":"<p>Tools: </p> <ul> <li>Wappalyzer</li> <li>BuiltWith</li> <li>Netcraft</li> <li>WhatWeb</li> </ul> <p>You can start to understand the stack with the used languages, frameworks, CMS and libraries used. </p>"},{"location":"security/playbooks/recon/#codebase-asset-hunting","title":"Codebase &amp; Asset Hunting","text":"<ul> <li>You can look for public GitHub repos by target name </li> <li>Identify exposed .git, .env, .bak, etc. in the Waybackmashine </li> <li>also looking for though Pastbin, Gist or leaks from your target can be helpful </li> </ul> <p>Here it is not unlikly to come across old credentials, forgotten endpoints or internal code what helps you extract how things are done to find the logic and structure behind it. </p>"},{"location":"security/playbooks/recon/#thrid-party-enumeration","title":"Thrid-Party Enumeration","text":"<p>Figuring out about third partries they use. </p> <ul> <li>SSO provider</li> <li>Marketing tools</li> <li>used CDN</li> <li>Library dependencies</li> </ul> <p>Mapping dependencies and weak links can help you find differenct attack vectors. </p>"},{"location":"security/playbooks/recon/#notes-to-take","title":"Notes to take:","text":"<p>You need to start building you documentation here. Here is what you write down: - Domains - Subdomains - Tech stacks - Notable files/ leaks</p> <p>Also you should start making a inital map about the internal sturcture. This helps you to fit everything else you find into its place.  </p>"},{"location":"security/playbooks/recon/#outcome","title":"Outcome","text":"<p>By the end of this stage this is what you should have:  </p> <ul> <li>A list of target domains/ subdomains</li> <li>Public known infrastructure</li> <li>Highlevel service stack</li> <li>Potentail weak links from external assets</li> <li>Initial attack surface mindmap</li> </ul>"},{"location":"security/playbooks/recon/#active-recon","title":"Active Recon","text":"<p>Definition</p> <p>Here you are interacting with the target's Infrastructure directly. You are scanning and probing. Since you are sending packages, here you are leaving fingerprints and should be aware of that. </p>"},{"location":"security/playbooks/recon/#port-scanning","title":"Port scanning","text":"<ul> <li>Discovering open ports and determine their state</li> <li>Understanding exposed surface area</li> <li>Tools: nmap, rustscan, masscan</li> </ul>"},{"location":"security/playbooks/recon/#service-enumation","title":"Service Enumation","text":"<ul> <li>Idenfy running services and versions</li> <li>Fingerprint protocols, grab banners, test endpoints</li> <li>Tools: nmap, netcat, telnet, whatweb, httpx</li> </ul>"},{"location":"security/playbooks/recon/#authentication-access-points","title":"Authentication &amp; Access Points","text":"<ul> <li>Scan for login portals across services: SSH, FTP, RDP, Telnet</li> <li>Identify entry points that may lead to further attack vectors</li> <li>Tools: hydra, ncrack, meduse </li> </ul>"},{"location":"security/playbooks/recon/#info-leaks","title":"Info Leaks","text":"<ul> <li>Interact with services to provoke behavior to test for leaks, misconfigs, or sloppy responses </li> <li>Think SMPT, VRFY, FTP misconfigs or SSH MOTD leaks</li> <li>Tools: netcat, curl, openssl</li> </ul>"},{"location":"security/playbooks/recon/#notes-to-take_1","title":"Notes to take:","text":"<p>Document everything you find. Put the new finds in the old documentation, mark the still active subdomains, fill out your map of the infrastructure. Complete with where you find which ports and services. </p>"},{"location":"security/playbooks/recon/#outcome_1","title":"Outcome","text":"<p>By the endof this stage this is what you should have: </p> <ul> <li>List of reachable hosts with open ports and active services</li> <li>Serivce versions with potential weak configs</li> <li>Authentication endpoints and any possible misconfigurations</li> <li>A prioritized attack surface with targets worth deeper inspection </li> <li>Clear specification what need Web Recon to start the next phase with. </li> </ul>"},{"location":"security/playbooks/recon/#web-recon","title":"Web Recon","text":"<p>Digging deep into web services. There is normally a lot to find. From hidden dirctories, files, over headers used. Find the login portals. Specifiy where attack surface is. </p>"},{"location":"security/playbooks/recon/#identifying-web-assets","title":"Identifying Web Assets","text":"<p>You should already have a pretty good idea of the web assets after the last steps. But you should make yourself a specified plan of what you need to takle in this section. </p>"},{"location":"security/playbooks/recon/#clientside-logic","title":"Clientside Logic","text":"<ul> <li>Parse JavaScript files manually or with tools </li> <li>Find API endpoints, secrets and tokens</li> <li>Map JS-based routing and hidden funktionality</li> </ul>"},{"location":"security/playbooks/recon/#input-vectors","title":"Input Vectors","text":"<ul> <li>Query strings, forms and hidden inputs</li> <li>File uploaders, search bars and filters</li> <li>Are there any client-side validations?</li> </ul>"},{"location":"security/playbooks/recon/#session-handling-authentication-behavior","title":"Session Handling &amp; Authentication Behavior","text":"<ul> <li>Cookie flags, token behavior, session expiry</li> <li>Authentication flows (login, rest, MFA)</li> <li>Redirect behavior, caching</li> <li>Version leaks, misconfigs </li> </ul>"},{"location":"security/playbooks/recon/#notes","title":"Notes","text":"<ul> <li>Put everything you find to your map</li> <li>Mark interesting targets, that might offer more</li> </ul>"},{"location":"security/playbooks/recon/#outcome_2","title":"Outcome","text":"<p>You should be able to tie findings to potential exploitation paths. Through the exploration of headers and forms, you have a solid understanding of what your targets exposes on the web and where to dig deeper. </p>"},{"location":"security/playbooks/recon/#enumeration","title":"Enumeration","text":"<p>Here you want to see what is used. Finding every service and protocol they use. You need to provoke, record and understand every response. </p>"},{"location":"security/playbooks/recon/#tools-to-use","title":"Tools to use:","text":"<ul> <li>SMB shares</li> <li>HTTPS services</li> <li>FTP</li> <li>DNS zone transfer attempts</li> <li>SNMP</li> </ul>"},{"location":"security/playbooks/recon/#vulnerability-enumeration","title":"Vulnerability Enumeration","text":"<p>Now that you have loads of information, it is time to look where you can actually get somewhere. Look for known vulnerabilities for services they use, use vuln scanner and look though CVEs. Match exposed services with weaknesses. </p>"},{"location":"security/playbooks/recon/#tools-to-use_1","title":"Tools to use:","text":"<ul> <li>Nikto</li> <li>Searchsploit</li> <li>CVE search</li> </ul>"},{"location":"security/playbooks/recon/#documentation","title":"Documentation","text":"<p>Most underated weapon. Espacially for recon. With down everything you have. Go over your notes. Make them usefull. You need to be able to find everything you wrote down in an instand. </p>"},{"location":"security/toolbelt/nmap/","title":"Nmap","text":"<p>Nmap (Network Mapper) is one of the most widely used tools in cybersecurity and networking.  It is primarily used for host discovery, port scanning,  service enumeration, and vulnerability detection.  Understanding it deeply is crucial  because it represents the foundation of reconnaissance,  both in offensive (red team, penetration testing, bug bounty)  and defensive (blue team, monitoring, threat hunting) contexts.</p>"},{"location":"security/toolbelt/nmap/#why-nmap-matters","title":"Why Nmap Matters","text":"<ul> <li>Red Teaming / Pentesting: First step in mapping the attack surface.</li> <li>Blue Teaming / Defense: Helps simulate what attackers see, validate firewall rules, and detect exposures.</li> <li>Bug Bounties: Identifies open ports and services that may lead to exploitable targets.</li> <li>Network Ops: Troubleshooting connectivity, inventorying assets, verifying configurations.</li> </ul> <p>Nmap is essentially a flashlight in the dark network.  It doesn\u2019t break in, but it shows you the doors, windows, and weak spots.</p>"},{"location":"security/toolbelt/nmap/#core-functions-of-nmap","title":"Core Functions of Nmap","text":""},{"location":"security/toolbelt/nmap/#1-host-discovery","title":"1. Host Discovery","text":"<ul> <li>Identifying live systems in a network.</li> <li>Techniques: ICMP echo requests, TCP SYN/ACK, ARP scanning, etc.</li> <li>Command example: <code>nmap -sn 192.168.1.0/24</code> (ping sweep)</li> </ul>"},{"location":"security/toolbelt/nmap/#2-port-scanning","title":"2. Port Scanning","text":"<ul> <li>Determining which ports are open/closed/filtered.</li> <li>Supports TCP connect, TCP SYN (stealth), UDP scans, etc.</li> <li>Example: <code>nmap -sS -p- target.com</code> (stealth scan all ports)</li> </ul>"},{"location":"security/toolbelt/nmap/#3-service-version-detection","title":"3. Service &amp; Version Detection","text":"<ul> <li>Identifies what service is running and its version.</li> <li><code>nmap -sV target.com</code></li> </ul>"},{"location":"security/toolbelt/nmap/#4-os-detection","title":"4. OS Detection","text":"<ul> <li>Fingerprinting OS based on TCP/IP stack behavior.</li> <li><code>nmap -O target.com</code></li> </ul>"},{"location":"security/toolbelt/nmap/#5-scripting-engine-nse","title":"5. Scripting Engine (NSE)","text":"<ul> <li>Extends Nmap with scripts for discovery, brute force, vulnerability detection, etc.</li> <li>Example: <code>nmap --script vuln target.com</code></li> </ul>"},{"location":"security/toolbelt/nmap/#6-timing-performance","title":"6. Timing &amp; Performance","text":"<ul> <li>Balances stealth and speed.</li> <li><code>-T0</code> (paranoid, very slow) \u2192 <code>-T5</code> (insane, very fast).</li> <li>Adjusts retries, parallelism, delays.</li> </ul>"},{"location":"security/toolbelt/nmap/#7-output-options","title":"7. Output Options","text":"<ul> <li>Normal, grepable, XML, JSON (with tools).</li> <li>Example: <code>nmap -oN scan.txt -oX scan.xml target.com</code></li> </ul>"},{"location":"security/toolbelt/nmap/#how-to-think-about-nmap","title":"How to Think About Nmap","text":""},{"location":"security/toolbelt/nmap/#offensive-perspective-red-team","title":"Offensive Perspective (Red Team)","text":"<ul> <li>Before exploitation comes discovery. </li> <li>Nmap tells you which targets are worth attention.  </li> <li>Combine with other tools (e.g., Gobuster for directories, Nikto for web scanning) after ports/services are known.  </li> </ul>"},{"location":"security/toolbelt/nmap/#defensive-perspective-blue-team","title":"Defensive Perspective (Blue Team)","text":"<ul> <li>Use Nmap against your own network: \u201cIf I scan like an attacker, what do I see?\u201d </li> <li>Detect weak firewall rules or unintended exposures.  </li> <li>Schedule recurring scans to ensure configurations hold.  </li> </ul>"},{"location":"security/toolbelt/nmap/#bug-bounty-perspective","title":"Bug Bounty Perspective","text":"<ul> <li>Running <code>nmap -sV --open -p-</code> against a scope can reveal forgotten services.  </li> <li>Combine with service-specific checks (e.g., default creds, outdated versions).  </li> <li>Often the bridge between blind reconnaissance and actionable attack vectors.  </li> </ul>"},{"location":"security/toolbelt/nmap/#integration-with-workflow","title":"Integration with Workflow","text":"<ul> <li>Feed results into SIEM for context.</li> <li>Export into formats consumable by tools (Metasploit, Nessus).</li> <li>Script automation: run scans nightly or integrate with CI/CD pipelines for devsecops.</li> </ul>"},{"location":"security/toolbelt/nmap/#key-takeaway","title":"Key Takeaway","text":"<p>Nmap isn\u2019t just a scanner\u2014it\u2019s the first lens into any unknown network. If you don\u2019t master Nmap, you\u2019re blind in both attack and defense. Every serious engagement starts with \u201cWhat\u2019s alive? What\u2019s open? What\u2019s running?\u201d That is the foundation on which everything else in cybersecurity is built.</p>"},{"location":"security/toolbelt/nmap/#integration","title":"Integration","text":"<ul> <li>Recon</li> </ul>"}]}